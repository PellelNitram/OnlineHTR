{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchmetrics.functional.text import word_error_rate\n",
    "from torchmetrics.functional.text import char_error_rate\n",
    "\n",
    "from src.models.carbune_module import CarbuneLitModule2\n",
    "from src.models.components.carbune2020_net import Carbune2020NetAttempt1\n",
    "from src.utils.io import load_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../logs/train/multiruns/2024-03-20_13-11-14/0/tensorboard/version_0/checkpoints/epoch=9999-step=1900000.ckpt'\n",
    "PATH = '../logs/train/multiruns/2024-03-27_14-06-58/0/checkpoints/epoch_epoch=029.ckpt'\n",
    "\n",
    "BASE_PATH = Path('../logs/train/multiruns/2024-03-28_11-36-50/0')\n",
    "CHECKPOINT_PATH = BASE_PATH / 'checkpoints/epoch000999.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like I don't have models saved :-D.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "1. [x] Add model checkpointing w/ new config.\n",
    "2. [x] RUn a short training just to get some model to play around with.\n",
    "3. Use some of the following links to load model for inference. Links:\n",
    "    - [1](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#save-hyperparameters), [2](https://lightning.ai/docs/pytorch/stable/common/trainer.html#inference-mode), [3](https://lightning.ai/docs/pytorch/stable/deploy/production_basic.html), [4](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html#nn-module-from-checkpoint).\n",
    "    - G\"pytorch lightning load model for inference\"\n",
    "    - !! https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#inference-in-production or\n",
    "    - https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#save-hyperparameters\n",
    "    - https://lightning.ai/forums/t/save-load-model-for-inference/542\n",
    "    - https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "4. Then load IAMonDB dataset and do inference. Consider using `Trainer` instead of DIY approach of doing inference. That's b/c it's easier and will not be seen in the promo video anyways.\n",
    "4. Then run full training to get `checkpoint` data from there to play around.\n",
    "4. Then load handwritten X++pagewise dataset and do inference on them\n",
    "4. Then look for method to draw stroke in Jupyter Notebook.\n",
    "\n",
    "*Note:* Make sure that I do correct pre-processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to complete point 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CarbuneLitModule2:\n\tUnexpected key(s) in state_dict: \"net.lstm_stack.weight_ih_l0\", \"net.lstm_stack.weight_hh_l0\", \"net.lstm_stack.bias_ih_l0\", \"net.lstm_stack.bias_hh_l0\", \"net.lstm_stack.weight_ih_l0_reverse\", \"net.lstm_stack.weight_hh_l0_reverse\", \"net.lstm_stack.bias_ih_l0_reverse\", \"net.lstm_stack.bias_hh_l0_reverse\", \"net.lstm_stack.weight_ih_l1\", \"net.lstm_stack.weight_hh_l1\", \"net.lstm_stack.bias_ih_l1\", \"net.lstm_stack.bias_hh_l1\", \"net.lstm_stack.weight_ih_l1_reverse\", \"net.lstm_stack.weight_hh_l1_reverse\", \"net.lstm_stack.bias_ih_l1_reverse\", \"net.lstm_stack.bias_hh_l1_reverse\", \"net.lstm_stack.weight_ih_l2\", \"net.lstm_stack.weight_hh_l2\", \"net.lstm_stack.bias_ih_l2\", \"net.lstm_stack.bias_hh_l2\", \"net.lstm_stack.weight_ih_l2_reverse\", \"net.lstm_stack.weight_hh_l2_reverse\", \"net.lstm_stack.bias_ih_l2_reverse\", \"net.lstm_stack.bias_hh_l2_reverse\", \"net.linear.weight\", \"net.linear.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCarbuneLitModule2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1561\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1488\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1561\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:89\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 89\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:169\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m strict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CarbuneLitModule2:\n\tUnexpected key(s) in state_dict: \"net.lstm_stack.weight_ih_l0\", \"net.lstm_stack.weight_hh_l0\", \"net.lstm_stack.bias_ih_l0\", \"net.lstm_stack.bias_hh_l0\", \"net.lstm_stack.weight_ih_l0_reverse\", \"net.lstm_stack.weight_hh_l0_reverse\", \"net.lstm_stack.bias_ih_l0_reverse\", \"net.lstm_stack.bias_hh_l0_reverse\", \"net.lstm_stack.weight_ih_l1\", \"net.lstm_stack.weight_hh_l1\", \"net.lstm_stack.bias_ih_l1\", \"net.lstm_stack.bias_hh_l1\", \"net.lstm_stack.weight_ih_l1_reverse\", \"net.lstm_stack.weight_hh_l1_reverse\", \"net.lstm_stack.bias_ih_l1_reverse\", \"net.lstm_stack.bias_hh_l1_reverse\", \"net.lstm_stack.weight_ih_l2\", \"net.lstm_stack.weight_hh_l2\", \"net.lstm_stack.bias_ih_l2\", \"net.lstm_stack.bias_hh_l2\", \"net.lstm_stack.weight_ih_l2_reverse\", \"net.lstm_stack.weight_hh_l2_reverse\", \"net.lstm_stack.bias_ih_l2_reverse\", \"net.lstm_stack.bias_hh_l2_reverse\", \"net.linear.weight\", \"net.linear.bias\". "
     ]
    }
   ],
   "source": [
    "model = CarbuneLitModule2.load_from_checkpoint(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Understand this problem! It has something todo w/ `nn.Module` input called `net`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2\n",
    "\n",
    "Based on [this](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html#save-hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH, map_location=lambda storage, loc: storage)\n",
    "# print(checkpoint[\"hyper_parameters\"])\n",
    "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch',\n",
       " 'global_step',\n",
       " 'pytorch-lightning_version',\n",
       " 'state_dict',\n",
       " 'loops',\n",
       " 'callbacks',\n",
       " 'optimizer_states',\n",
       " 'lr_schedulers',\n",
       " 'hparams_name',\n",
       " 'hyper_parameters',\n",
       " 'datamodule_hparams_name',\n",
       " 'datamodule_hyper_parameters']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder': GreedyCTCDecoder(),\n",
       " 'net': functools.partial(<class 'src.models.components.carbune2020_net.Carbune2020NetAttempt1'>, nodes_per_layer=64, number_of_layers=3, dropout=0.0),\n",
       " 'optimizer': functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.0001, weight_decay=0.0),\n",
       " 'scheduler': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.utils.decoders.GreedyCTCDecoder"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(checkpoint['hyper_parameters']['decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'src.models.components.carbune2020_net.Carbune2020NetAttempt1'>, nodes_per_layer=64, number_of_layers=3, dropout=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['hyper_parameters']['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kwargs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['hparams_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['net.lstm_stack.weight_ih_l0',\n",
       " 'net.lstm_stack.weight_hh_l0',\n",
       " 'net.lstm_stack.bias_ih_l0',\n",
       " 'net.lstm_stack.bias_hh_l0',\n",
       " 'net.lstm_stack.weight_ih_l0_reverse',\n",
       " 'net.lstm_stack.weight_hh_l0_reverse',\n",
       " 'net.lstm_stack.bias_ih_l0_reverse',\n",
       " 'net.lstm_stack.bias_hh_l0_reverse',\n",
       " 'net.lstm_stack.weight_ih_l1',\n",
       " 'net.lstm_stack.weight_hh_l1',\n",
       " 'net.lstm_stack.bias_ih_l1',\n",
       " 'net.lstm_stack.bias_hh_l1',\n",
       " 'net.lstm_stack.weight_ih_l1_reverse',\n",
       " 'net.lstm_stack.weight_hh_l1_reverse',\n",
       " 'net.lstm_stack.bias_ih_l1_reverse',\n",
       " 'net.lstm_stack.bias_hh_l1_reverse',\n",
       " 'net.lstm_stack.weight_ih_l2',\n",
       " 'net.lstm_stack.weight_hh_l2',\n",
       " 'net.lstm_stack.bias_ih_l2',\n",
       " 'net.lstm_stack.bias_hh_l2',\n",
       " 'net.lstm_stack.weight_ih_l2_reverse',\n",
       " 'net.lstm_stack.weight_hh_l2_reverse',\n",
       " 'net.lstm_stack.bias_ih_l2_reverse',\n",
       " 'net.lstm_stack.bias_hh_l2_reverse',\n",
       " 'net.linear.weight',\n",
       " 'net.linear.bias']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(checkpoint['state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch',\n",
       " 'global_step',\n",
       " 'pytorch-lightning_version',\n",
       " 'state_dict',\n",
       " 'loops',\n",
       " 'callbacks',\n",
       " 'optimizer_states',\n",
       " 'lr_schedulers',\n",
       " 'hparams_name',\n",
       " 'hyper_parameters',\n",
       " 'datamodule_hparams_name',\n",
       " 'datamodule_hyper_parameters']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.lstm_stack.weight_ih_l0',\n",
       "              tensor([[ 0.1082,  0.1159, -0.0167],\n",
       "                      [ 0.1280, -0.0162,  0.0384],\n",
       "                      [-0.0613,  0.0728,  0.1095],\n",
       "                      [-0.0787,  0.1204,  0.0364],\n",
       "                      [ 0.0909,  0.0185,  0.0585],\n",
       "                      [-0.0046,  0.1090,  0.0315],\n",
       "                      [-0.0495,  0.0232, -0.0491],\n",
       "                      [-0.0150, -0.0515,  0.0826],\n",
       "                      [-0.0853, -0.0450, -0.0219],\n",
       "                      [-0.0618, -0.0014, -0.1100],\n",
       "                      [ 0.1260, -0.1189,  0.1098],\n",
       "                      [ 0.0275, -0.0337,  0.0840],\n",
       "                      [ 0.0324,  0.0886,  0.0226],\n",
       "                      [-0.0400,  0.0323, -0.0354],\n",
       "                      [ 0.0649,  0.1233,  0.0845],\n",
       "                      [-0.0416,  0.0848,  0.0354],\n",
       "                      [ 0.0753, -0.0667, -0.1126],\n",
       "                      [-0.0494, -0.0995,  0.1013],\n",
       "                      [ 0.0485,  0.0637,  0.0520],\n",
       "                      [ 0.0067,  0.1064, -0.0800],\n",
       "                      [ 0.0209, -0.0980,  0.0451],\n",
       "                      [-0.0388,  0.0422, -0.0233],\n",
       "                      [ 0.1106, -0.0815, -0.0754],\n",
       "                      [-0.0658,  0.1207,  0.0504],\n",
       "                      [ 0.1335, -0.0908, -0.1109],\n",
       "                      [-0.0850, -0.0844,  0.0634],\n",
       "                      [ 0.0579,  0.1070, -0.0515],\n",
       "                      [-0.0837,  0.0733, -0.0445],\n",
       "                      [ 0.0751, -0.0291,  0.0683],\n",
       "                      [-0.0967, -0.0629,  0.0384],\n",
       "                      [ 0.0211, -0.0311,  0.0683],\n",
       "                      [ 0.0873, -0.0933, -0.0639],\n",
       "                      [ 0.1255, -0.0312, -0.0333],\n",
       "                      [-0.1078, -0.0841,  0.0448],\n",
       "                      [-0.0143, -0.1034, -0.0033],\n",
       "                      [-0.0753, -0.1163, -0.0589],\n",
       "                      [-0.1183, -0.0729,  0.1162],\n",
       "                      [ 0.0141,  0.0253, -0.1293],\n",
       "                      [-0.0688, -0.0285,  0.0328],\n",
       "                      [-0.0972, -0.0661, -0.0618],\n",
       "                      [ 0.0052, -0.0410, -0.0039],\n",
       "                      [-0.0722, -0.0735, -0.0604],\n",
       "                      [-0.0309, -0.0872,  0.1168],\n",
       "                      [-0.0142,  0.1183,  0.0498],\n",
       "                      [-0.0925,  0.0737, -0.0210],\n",
       "                      [-0.0361, -0.0933, -0.1129],\n",
       "                      [ 0.0376, -0.0256,  0.0501],\n",
       "                      [-0.0907,  0.0832, -0.0794],\n",
       "                      [-0.0158,  0.0137,  0.0683],\n",
       "                      [ 0.0951,  0.1143, -0.0984],\n",
       "                      [ 0.0428, -0.0422, -0.0023],\n",
       "                      [-0.0900,  0.1104, -0.0882],\n",
       "                      [ 0.0800,  0.0311,  0.0538],\n",
       "                      [-0.0550,  0.1258,  0.0401],\n",
       "                      [ 0.0099, -0.1230,  0.0419],\n",
       "                      [-0.0301, -0.0683,  0.0956],\n",
       "                      [ 0.0409, -0.0812, -0.0502],\n",
       "                      [ 0.0055,  0.0594, -0.0205],\n",
       "                      [-0.0583, -0.0299, -0.0803],\n",
       "                      [ 0.0544,  0.0872, -0.1153],\n",
       "                      [ 0.0387,  0.0742,  0.0322],\n",
       "                      [-0.0314,  0.0780,  0.0788],\n",
       "                      [ 0.0507, -0.0181, -0.0292],\n",
       "                      [ 0.0268, -0.0096, -0.0285],\n",
       "                      [ 0.0927,  0.0949,  0.0005],\n",
       "                      [-0.0148, -0.0044,  0.0057],\n",
       "                      [ 0.0296,  0.0352, -0.1139],\n",
       "                      [-0.0331,  0.0924,  0.0618],\n",
       "                      [-0.0077, -0.0767, -0.0779],\n",
       "                      [-0.0989, -0.0537,  0.0553],\n",
       "                      [ 0.0885,  0.0521, -0.1017],\n",
       "                      [-0.0743, -0.0198,  0.1218],\n",
       "                      [ 0.0316, -0.0428,  0.0652],\n",
       "                      [-0.0342, -0.0941,  0.1046],\n",
       "                      [-0.0437, -0.0372, -0.1112],\n",
       "                      [ 0.0904,  0.1032,  0.0523],\n",
       "                      [-0.0744, -0.1164, -0.0889],\n",
       "                      [ 0.0945,  0.0588,  0.1065],\n",
       "                      [ 0.0780,  0.0316,  0.0113],\n",
       "                      [-0.0820, -0.1197, -0.1038],\n",
       "                      [ 0.0482, -0.0716, -0.0279],\n",
       "                      [-0.0732, -0.0217, -0.0893],\n",
       "                      [-0.0690,  0.0291, -0.0244],\n",
       "                      [ 0.0861, -0.0494, -0.0830],\n",
       "                      [-0.0090, -0.0698, -0.0252],\n",
       "                      [-0.1147,  0.0743, -0.0827],\n",
       "                      [ 0.0719,  0.0684,  0.0986],\n",
       "                      [-0.0872,  0.0782, -0.0504],\n",
       "                      [ 0.0597,  0.1293, -0.0043],\n",
       "                      [ 0.0118, -0.0409, -0.0916],\n",
       "                      [ 0.0732, -0.1368,  0.0909],\n",
       "                      [ 0.0868,  0.1247, -0.0363],\n",
       "                      [-0.1031,  0.0315,  0.0686],\n",
       "                      [-0.1240, -0.0300, -0.0745],\n",
       "                      [-0.0125, -0.0639, -0.0527],\n",
       "                      [-0.0369, -0.1215,  0.1054],\n",
       "                      [ 0.1159, -0.0313, -0.0032],\n",
       "                      [-0.0380, -0.1088, -0.1086],\n",
       "                      [ 0.0596, -0.0564, -0.0672],\n",
       "                      [ 0.0006, -0.0534, -0.0302],\n",
       "                      [-0.0049, -0.0175, -0.0519],\n",
       "                      [-0.0464, -0.0947,  0.1182],\n",
       "                      [-0.0366,  0.0326, -0.0300],\n",
       "                      [ 0.0230,  0.1111,  0.0704],\n",
       "                      [-0.1035,  0.0455,  0.1235],\n",
       "                      [ 0.0455,  0.0721,  0.1358],\n",
       "                      [-0.0072,  0.0302, -0.0749],\n",
       "                      [-0.0149,  0.0865,  0.0750],\n",
       "                      [-0.0659, -0.0886, -0.0722],\n",
       "                      [-0.1159, -0.1085, -0.0232],\n",
       "                      [ 0.0861,  0.0186, -0.0934],\n",
       "                      [-0.0882,  0.0578, -0.0808],\n",
       "                      [-0.0021,  0.0473, -0.0445],\n",
       "                      [-0.0143, -0.0120, -0.0302],\n",
       "                      [-0.0520, -0.1220, -0.0897],\n",
       "                      [-0.0634,  0.1236, -0.0569],\n",
       "                      [-0.0707,  0.0321,  0.0477],\n",
       "                      [ 0.0811,  0.0825,  0.0823],\n",
       "                      [-0.1106, -0.0004,  0.0890],\n",
       "                      [-0.0229, -0.0617,  0.1078],\n",
       "                      [-0.0337, -0.0840, -0.0996],\n",
       "                      [ 0.0170,  0.0645,  0.0390],\n",
       "                      [ 0.0379, -0.1035, -0.1036],\n",
       "                      [ 0.0120,  0.1233,  0.0819],\n",
       "                      [-0.0631, -0.0116, -0.0825],\n",
       "                      [-0.0468,  0.0205,  0.0816],\n",
       "                      [ 0.1075, -0.1147,  0.0875],\n",
       "                      [-0.0747,  0.0583,  0.1182],\n",
       "                      [-0.0106,  0.1111, -0.1188],\n",
       "                      [-0.0347,  0.0639, -0.0142],\n",
       "                      [-0.0262, -0.0541,  0.0855],\n",
       "                      [ 0.0484,  0.0492, -0.0832],\n",
       "                      [-0.0999,  0.0146,  0.0386],\n",
       "                      [-0.0449, -0.0451,  0.0973],\n",
       "                      [ 0.0186, -0.0037, -0.0222],\n",
       "                      [-0.1124, -0.1084, -0.0591],\n",
       "                      [-0.0768,  0.0497, -0.0497],\n",
       "                      [-0.0622,  0.1317,  0.0303],\n",
       "                      [ 0.1019, -0.0685, -0.0383],\n",
       "                      [ 0.0391, -0.0775, -0.0886],\n",
       "                      [ 0.0066, -0.0356, -0.0812],\n",
       "                      [ 0.0728,  0.1010,  0.0190],\n",
       "                      [-0.0335, -0.1096, -0.0573],\n",
       "                      [ 0.0447,  0.0465, -0.0030],\n",
       "                      [-0.0590,  0.0794, -0.1091],\n",
       "                      [ 0.0806, -0.0496,  0.0035],\n",
       "                      [-0.0367,  0.0197, -0.0497],\n",
       "                      [ 0.0997, -0.0123,  0.1063],\n",
       "                      [ 0.1329, -0.0733, -0.0785],\n",
       "                      [ 0.1045,  0.0948, -0.0913],\n",
       "                      [-0.0004, -0.1112, -0.0944],\n",
       "                      [ 0.0329,  0.0227,  0.0352],\n",
       "                      [-0.0217,  0.1030,  0.0302],\n",
       "                      [-0.0611, -0.0191,  0.0427],\n",
       "                      [ 0.0565, -0.0832,  0.0596],\n",
       "                      [-0.0708, -0.0966, -0.0752],\n",
       "                      [ 0.1210,  0.1013,  0.1124],\n",
       "                      [ 0.0738,  0.0927, -0.0165],\n",
       "                      [-0.0697,  0.0552, -0.0658],\n",
       "                      [-0.0817, -0.0426,  0.0289],\n",
       "                      [ 0.0533, -0.0369, -0.0845],\n",
       "                      [ 0.0295, -0.0689, -0.0688],\n",
       "                      [ 0.0524, -0.0092,  0.1015],\n",
       "                      [ 0.1114,  0.0488,  0.0330],\n",
       "                      [ 0.0199,  0.0101, -0.0179],\n",
       "                      [-0.0115,  0.0595,  0.1030],\n",
       "                      [-0.0456, -0.0403, -0.0434],\n",
       "                      [-0.0728,  0.0320,  0.0809],\n",
       "                      [ 0.0931,  0.0605, -0.0967],\n",
       "                      [-0.0794, -0.0152, -0.0354],\n",
       "                      [-0.0014, -0.1024,  0.0271],\n",
       "                      [-0.1061, -0.0674, -0.1148],\n",
       "                      [ 0.0958, -0.1067,  0.0812],\n",
       "                      [ 0.0065, -0.0261,  0.0889],\n",
       "                      [-0.0099,  0.0744,  0.0918],\n",
       "                      [-0.1201,  0.0485,  0.0119],\n",
       "                      [ 0.0143,  0.0167,  0.0216],\n",
       "                      [-0.0596, -0.0187,  0.1194],\n",
       "                      [ 0.0728,  0.0059, -0.1289],\n",
       "                      [ 0.0021, -0.0811,  0.0982],\n",
       "                      [-0.0628,  0.0036, -0.0146],\n",
       "                      [ 0.0346,  0.1053,  0.0243],\n",
       "                      [ 0.0595,  0.0914,  0.0880],\n",
       "                      [-0.0555, -0.0341,  0.0479],\n",
       "                      [-0.0469,  0.0713, -0.0401],\n",
       "                      [-0.0959,  0.0444,  0.0080],\n",
       "                      [ 0.0687,  0.1113,  0.0983],\n",
       "                      [ 0.1280,  0.0028, -0.0981],\n",
       "                      [-0.0972, -0.0705, -0.1196],\n",
       "                      [-0.0754, -0.1024, -0.1281],\n",
       "                      [-0.0786, -0.1184, -0.0806],\n",
       "                      [ 0.0602,  0.0920, -0.0246],\n",
       "                      [-0.0237,  0.0780, -0.0490],\n",
       "                      [-0.0459,  0.0871, -0.0957],\n",
       "                      [ 0.0148,  0.1095,  0.0208],\n",
       "                      [ 0.0470, -0.0608,  0.0113],\n",
       "                      [ 0.0053,  0.0317,  0.0470],\n",
       "                      [ 0.1217, -0.0833,  0.0168],\n",
       "                      [-0.0537, -0.1077, -0.0013],\n",
       "                      [-0.1094,  0.0866,  0.0156],\n",
       "                      [-0.0539,  0.0763, -0.1048],\n",
       "                      [-0.0350, -0.0376, -0.0928],\n",
       "                      [-0.0664, -0.0332,  0.1081],\n",
       "                      [ 0.1274,  0.0864, -0.0679],\n",
       "                      [-0.0690,  0.0965,  0.0569],\n",
       "                      [ 0.0041,  0.0156, -0.0995],\n",
       "                      [-0.0294,  0.1320, -0.0185],\n",
       "                      [ 0.0068, -0.0922, -0.0568],\n",
       "                      [ 0.0041, -0.0685, -0.0030],\n",
       "                      [ 0.0497, -0.1229,  0.0359],\n",
       "                      [-0.0701, -0.0492,  0.0605],\n",
       "                      [ 0.1083, -0.0257, -0.0426],\n",
       "                      [-0.1000, -0.0771, -0.0962],\n",
       "                      [-0.0243,  0.0302, -0.1126],\n",
       "                      [ 0.1181,  0.0730, -0.1131],\n",
       "                      [-0.0510,  0.0486, -0.0170],\n",
       "                      [-0.0004, -0.0442,  0.1136],\n",
       "                      [-0.0571,  0.0912,  0.0208],\n",
       "                      [ 0.0383,  0.0877, -0.0074],\n",
       "                      [-0.0775, -0.0132,  0.0961],\n",
       "                      [-0.0931,  0.0291, -0.1232],\n",
       "                      [ 0.0660,  0.0457,  0.0056],\n",
       "                      [ 0.0512,  0.0001,  0.0663],\n",
       "                      [-0.0977, -0.0210,  0.0583],\n",
       "                      [ 0.1355,  0.0743, -0.0799],\n",
       "                      [ 0.1092, -0.0404, -0.0135],\n",
       "                      [-0.1003, -0.0323,  0.0988],\n",
       "                      [ 0.0277, -0.0834,  0.0486],\n",
       "                      [-0.0490,  0.1206, -0.1172],\n",
       "                      [-0.0407, -0.1338, -0.0567],\n",
       "                      [ 0.0527,  0.1331,  0.0342],\n",
       "                      [ 0.1354,  0.0122,  0.0851],\n",
       "                      [ 0.1050,  0.1084, -0.0652],\n",
       "                      [ 0.1274,  0.0879, -0.0459],\n",
       "                      [-0.0477, -0.0935,  0.0434],\n",
       "                      [-0.0906,  0.0635,  0.0504],\n",
       "                      [-0.0953,  0.0214,  0.0031],\n",
       "                      [ 0.0697,  0.0809, -0.1124],\n",
       "                      [ 0.1164,  0.1071,  0.0512],\n",
       "                      [-0.1022, -0.0519, -0.0238],\n",
       "                      [-0.0213,  0.0580,  0.0547],\n",
       "                      [ 0.0973, -0.0466,  0.0406],\n",
       "                      [ 0.0558, -0.0923, -0.1098],\n",
       "                      [-0.0613,  0.0819, -0.1142],\n",
       "                      [-0.0956,  0.0587,  0.0807],\n",
       "                      [ 0.1154, -0.0820, -0.0788],\n",
       "                      [ 0.0724,  0.0959,  0.0776],\n",
       "                      [ 0.0082,  0.0379,  0.1070],\n",
       "                      [-0.0676, -0.0697,  0.1005],\n",
       "                      [-0.0741, -0.0789,  0.1027],\n",
       "                      [ 0.0525,  0.0532, -0.0399],\n",
       "                      [ 0.0081,  0.1051, -0.0633],\n",
       "                      [ 0.0107,  0.0693, -0.0767],\n",
       "                      [ 0.1346, -0.0498, -0.0168],\n",
       "                      [-0.0299, -0.0776, -0.1188],\n",
       "                      [ 0.0840,  0.0457, -0.1066]], device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l0',\n",
       "              tensor([[-0.0936,  0.1365,  0.0602,  ..., -0.0583,  0.0630,  0.0064],\n",
       "                      [-0.1229, -0.0555, -0.0773,  ..., -0.0077,  0.0778,  0.0513],\n",
       "                      [-0.0441, -0.0517, -0.0313,  ..., -0.0467,  0.1029,  0.0135],\n",
       "                      ...,\n",
       "                      [ 0.0547, -0.0012,  0.0061,  ..., -0.0579,  0.0690,  0.0717],\n",
       "                      [-0.0228, -0.0105, -0.0874,  ...,  0.1179,  0.0570, -0.0504],\n",
       "                      [ 0.0883,  0.0983,  0.0097,  ...,  0.0679,  0.0834,  0.0414]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l0',\n",
       "              tensor([ 0.0049, -0.0685, -0.0649,  0.0850, -0.0780, -0.0484,  0.0726, -0.0627,\n",
       "                      -0.0833,  0.0412,  0.0671, -0.1066,  0.0287, -0.0951,  0.0652,  0.0814,\n",
       "                       0.0399,  0.1207, -0.0116, -0.0409,  0.0469,  0.0417, -0.0476, -0.0735,\n",
       "                      -0.0247,  0.0646,  0.0660, -0.0622,  0.1052, -0.0924, -0.0162,  0.0334,\n",
       "                      -0.0790,  0.1267, -0.0483,  0.0842, -0.0040, -0.0591,  0.1303, -0.0012,\n",
       "                       0.0270,  0.1301, -0.1057,  0.1116, -0.0485, -0.0934,  0.0713, -0.0263,\n",
       "                      -0.0865, -0.0621,  0.0921,  0.0582,  0.0071,  0.0768,  0.0381, -0.1051,\n",
       "                       0.0371,  0.1002,  0.0014, -0.0045,  0.1322, -0.0223,  0.1205,  0.1216,\n",
       "                       0.1139,  0.0464,  0.0340,  0.0452, -0.1159, -0.0364, -0.0611, -0.0175,\n",
       "                      -0.0491, -0.0269, -0.0720, -0.0842,  0.0532,  0.1233, -0.0382, -0.0695,\n",
       "                      -0.0443, -0.0485, -0.1090,  0.1186,  0.0980,  0.0969, -0.0563, -0.0739,\n",
       "                       0.1332, -0.0629, -0.0918, -0.1109,  0.0375, -0.0162, -0.0779,  0.1093,\n",
       "                      -0.0582,  0.0211,  0.0754,  0.0701,  0.0956, -0.0043,  0.0779,  0.0029,\n",
       "                       0.0213, -0.0608,  0.0894,  0.0395,  0.0383, -0.0016,  0.0524, -0.1087,\n",
       "                       0.1155,  0.0972,  0.0783, -0.0011, -0.1034, -0.0212, -0.0871, -0.0713,\n",
       "                       0.1114, -0.0032,  0.1377, -0.0532, -0.0488, -0.0867,  0.0517,  0.0584,\n",
       "                       0.0507,  0.1211,  0.0747, -0.1276,  0.0050,  0.1219,  0.0959,  0.0491,\n",
       "                      -0.0719, -0.1187,  0.1332, -0.0478,  0.0553, -0.0351, -0.0540,  0.0573,\n",
       "                       0.1059, -0.0281,  0.0422,  0.0591, -0.0073,  0.0290,  0.0498,  0.1204,\n",
       "                      -0.0348,  0.1088,  0.0047,  0.0423, -0.1008,  0.0845,  0.1043,  0.0318,\n",
       "                      -0.0072,  0.0452, -0.1115, -0.1179,  0.0841, -0.1255, -0.0412, -0.0890,\n",
       "                      -0.1213, -0.0654, -0.0129, -0.1112, -0.1089, -0.0900, -0.0028, -0.0448,\n",
       "                       0.0793, -0.1190, -0.1203, -0.0415,  0.1381,  0.1262, -0.0291, -0.0464,\n",
       "                       0.0045, -0.0057,  0.0247, -0.0445, -0.0154,  0.0112,  0.0707, -0.0663,\n",
       "                      -0.0126,  0.0759,  0.0819,  0.0808, -0.0317,  0.0416, -0.0339,  0.1070,\n",
       "                       0.0845, -0.0994,  0.0738,  0.1294,  0.0462, -0.0978,  0.0929,  0.0198,\n",
       "                      -0.0358,  0.0532,  0.1097,  0.0655, -0.0855,  0.0564, -0.0689, -0.1080,\n",
       "                      -0.0486,  0.0785,  0.1093,  0.0301,  0.0763, -0.1188, -0.0626, -0.0685,\n",
       "                      -0.0951, -0.0651, -0.0761, -0.0942,  0.0092, -0.0471,  0.0186, -0.0072,\n",
       "                       0.0133, -0.1010, -0.0905, -0.1020,  0.1002,  0.0121, -0.1046, -0.0361,\n",
       "                       0.0120, -0.0836,  0.1124,  0.0932,  0.0433, -0.0089,  0.0860,  0.0213,\n",
       "                       0.0237,  0.0266, -0.0957,  0.0452,  0.0551,  0.0906,  0.0633,  0.1185],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l0',\n",
       "              tensor([-5.3635e-02,  2.3412e-02, -9.2433e-02,  1.2036e-01, -7.1819e-03,\n",
       "                      -9.4966e-02,  8.9898e-02,  1.5594e-02, -2.2594e-02,  1.2521e-01,\n",
       "                      -5.2722e-02, -5.5326e-02, -3.0175e-02,  1.5634e-02, -8.4658e-02,\n",
       "                       4.0097e-02, -1.2316e-01, -6.8705e-02, -6.0421e-02, -8.2033e-02,\n",
       "                       4.1706e-02,  5.9132e-02, -2.2344e-02, -2.8775e-02,  1.5998e-02,\n",
       "                      -8.8596e-02, -1.0542e-01, -8.7770e-02, -9.1147e-02,  1.8132e-02,\n",
       "                       9.9188e-02,  9.2050e-02, -6.5878e-02,  8.2509e-02,  1.2275e-01,\n",
       "                      -1.6221e-02, -4.9768e-02, -1.0703e-01,  4.4419e-03, -3.5679e-02,\n",
       "                       3.6286e-02, -1.0226e-01,  6.8784e-05,  3.2985e-02, -1.7908e-02,\n",
       "                      -1.1199e-02,  1.2042e-01,  6.6345e-02, -7.9718e-02, -5.7443e-02,\n",
       "                       6.8940e-02,  5.7916e-02, -9.2085e-02, -7.2843e-02, -3.8418e-02,\n",
       "                      -2.6683e-02,  2.0544e-02,  4.2022e-02, -4.5140e-02, -5.9986e-02,\n",
       "                       7.9446e-02, -8.4066e-02, -1.8037e-02, -9.9993e-02, -8.2246e-02,\n",
       "                       5.9886e-02, -6.4618e-03,  1.1797e-01,  1.2250e-01, -9.0530e-02,\n",
       "                      -5.7881e-02,  2.9283e-02, -2.2691e-03, -1.0109e-01, -6.1283e-02,\n",
       "                      -6.0349e-02,  2.5761e-02,  5.4432e-02,  8.9180e-02,  1.1881e-01,\n",
       "                      -6.8251e-02,  9.3287e-02, -5.8957e-02, -9.8583e-02, -4.0751e-02,\n",
       "                       6.1540e-02,  2.9061e-02, -9.9918e-02,  4.7014e-02,  7.9146e-03,\n",
       "                       1.0406e-01, -7.7404e-02, -1.0419e-01, -7.3737e-03, -5.1787e-02,\n",
       "                      -1.8409e-02, -2.2368e-02,  1.3490e-01, -3.2526e-03, -1.1068e-01,\n",
       "                      -8.2547e-02,  7.2048e-03,  8.3979e-02,  4.3036e-02, -1.1858e-01,\n",
       "                       3.0813e-02,  1.0131e-01, -2.9068e-02,  7.1356e-02,  1.1185e-01,\n",
       "                       1.0687e-01,  3.2707e-02, -1.0659e-01, -1.0770e-01,  1.0383e-01,\n",
       "                      -3.6790e-02,  1.2035e-01,  9.2940e-02, -9.8805e-02,  4.5047e-02,\n",
       "                      -9.0762e-02, -7.9392e-02,  1.0116e-01,  1.2239e-01,  6.9961e-02,\n",
       "                       7.1537e-02,  1.8641e-02,  9.2928e-02, -1.2958e-01,  7.4353e-02,\n",
       "                       1.4305e-02, -5.0467e-02, -7.1442e-02,  5.9703e-02, -1.8532e-02,\n",
       "                       1.4301e-02, -3.9103e-02, -1.6929e-02, -3.1957e-02, -1.2564e-01,\n",
       "                       4.2438e-02, -1.9390e-02, -4.9075e-02,  9.4360e-02, -6.8407e-02,\n",
       "                      -1.5347e-02, -1.2610e-01, -3.7841e-02,  1.0164e-01,  1.0788e-02,\n",
       "                       7.7305e-02,  1.1339e-01,  4.4568e-02,  1.0448e-01,  4.2649e-02,\n",
       "                       6.7342e-02, -1.0731e-01,  9.2990e-02,  4.0739e-02,  2.1942e-02,\n",
       "                      -1.3361e-01,  8.3166e-02,  5.4674e-02, -1.0419e-01,  9.8437e-02,\n",
       "                       1.0268e-01, -2.4983e-02, -5.2144e-02, -1.2154e-02, -1.1772e-01,\n",
       "                      -1.2331e-01, -2.8236e-02, -5.6098e-02,  1.2165e-01,  7.5164e-02,\n",
       "                      -4.6224e-02, -1.3578e-01,  3.9292e-02, -2.1679e-02, -6.9622e-02,\n",
       "                       1.2412e-01,  9.0605e-02, -6.0809e-02,  9.4065e-02, -1.2193e-01,\n",
       "                      -1.1463e-01,  7.1212e-02,  8.5479e-02, -3.5382e-02, -3.6638e-02,\n",
       "                      -1.2528e-01,  5.4282e-02,  9.2032e-03, -8.0675e-02, -9.6465e-02,\n",
       "                       8.3670e-02, -1.0603e-01,  4.0234e-02,  1.2290e-01, -3.5856e-02,\n",
       "                       8.4084e-02,  6.8678e-02, -1.5047e-02, -7.0361e-02, -6.2008e-02,\n",
       "                      -1.2084e-01,  3.0584e-02,  4.1929e-02, -3.4654e-02,  6.5638e-02,\n",
       "                       4.0087e-03,  4.7044e-02,  1.3458e-01,  1.2121e-01,  1.0814e-01,\n",
       "                      -4.2979e-02,  1.6030e-02, -2.4982e-02,  4.9258e-02,  6.6669e-02,\n",
       "                       2.0233e-02, -3.9692e-02,  1.9405e-02, -8.9612e-02, -9.8247e-02,\n",
       "                      -8.6010e-03,  1.5919e-03, -1.5951e-02,  4.7408e-02,  5.0535e-02,\n",
       "                       4.3447e-02,  4.3805e-02, -2.3390e-03,  3.5833e-02, -7.3489e-02,\n",
       "                      -6.8729e-02,  2.7872e-02,  8.6292e-02,  7.0708e-03,  1.2562e-01,\n",
       "                       1.1428e-01, -1.2562e-01, -4.6298e-02,  4.6922e-02,  7.2265e-03,\n",
       "                       5.4581e-02, -5.5350e-02,  5.5366e-02, -5.8838e-02,  1.9776e-02,\n",
       "                      -8.6625e-02, -2.6174e-02,  8.9272e-02,  7.8090e-02, -8.6150e-02,\n",
       "                       8.3724e-02], device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_ih_l0_reverse',\n",
       "              tensor([[-1.8596e-02, -9.5807e-02,  1.1305e-01],\n",
       "                      [ 5.5902e-02,  2.6469e-02,  5.3177e-02],\n",
       "                      [ 4.8573e-02, -1.2281e-01,  6.2918e-02],\n",
       "                      [ 1.0449e-01,  2.8097e-02, -2.2379e-02],\n",
       "                      [ 2.8951e-02, -1.4381e-03,  3.2358e-02],\n",
       "                      [-7.2460e-02,  7.3539e-02,  1.1547e-02],\n",
       "                      [ 2.0877e-02, -5.9372e-02,  1.2159e-01],\n",
       "                      [-7.7771e-02, -5.3833e-02, -7.2527e-02],\n",
       "                      [ 9.5987e-02, -5.5415e-02,  1.9309e-03],\n",
       "                      [ 4.1147e-03,  8.1204e-02, -9.2952e-02],\n",
       "                      [-5.1864e-02, -1.0950e-01, -1.4670e-02],\n",
       "                      [-1.1007e-01, -6.3893e-03,  4.4530e-02],\n",
       "                      [ 2.5230e-02,  2.4348e-02, -1.3108e-02],\n",
       "                      [-7.6866e-02, -3.1900e-02,  1.0310e-01],\n",
       "                      [ 3.7000e-02,  9.6386e-03, -2.3913e-02],\n",
       "                      [ 9.7138e-02,  9.4758e-02,  4.0047e-02],\n",
       "                      [ 1.0137e-01,  2.2371e-02,  1.5470e-02],\n",
       "                      [ 4.2827e-02, -1.1172e-01,  8.8174e-02],\n",
       "                      [-5.1676e-02, -6.7157e-02,  5.9397e-03],\n",
       "                      [-8.8025e-02, -7.6454e-02,  1.0708e-01],\n",
       "                      [-7.3427e-03,  3.3227e-02,  3.8055e-02],\n",
       "                      [ 1.1299e-01, -6.7390e-02, -7.3662e-02],\n",
       "                      [ 1.3243e-01, -7.0875e-02, -1.1033e-01],\n",
       "                      [-9.0056e-03,  8.2900e-02,  6.8612e-02],\n",
       "                      [-7.1230e-02, -8.4550e-02,  5.2783e-02],\n",
       "                      [-8.1174e-02,  6.9086e-02, -2.8121e-02],\n",
       "                      [-3.9788e-02, -1.1739e-02,  1.1228e-01],\n",
       "                      [-6.8605e-02, -8.9828e-02,  5.7245e-02],\n",
       "                      [ 6.5834e-02, -3.5593e-02,  8.8408e-02],\n",
       "                      [-1.6805e-02, -6.2495e-02, -8.1714e-02],\n",
       "                      [-5.6681e-02, -6.3707e-02,  3.8889e-02],\n",
       "                      [-1.5071e-02,  8.0913e-02, -5.2910e-02],\n",
       "                      [ 8.6012e-02,  1.1421e-01, -1.5247e-02],\n",
       "                      [-5.7098e-02,  5.0051e-02, -1.0579e-01],\n",
       "                      [ 9.0108e-02,  8.5250e-02, -2.6271e-03],\n",
       "                      [-6.4215e-02,  2.8825e-02,  1.0373e-01],\n",
       "                      [ 2.9750e-02,  3.6220e-02,  6.7579e-02],\n",
       "                      [ 8.3679e-02,  3.9942e-02, -5.5156e-02],\n",
       "                      [ 1.6932e-02, -6.6275e-02,  7.6522e-02],\n",
       "                      [-6.8486e-02,  1.0486e-01,  4.8372e-02],\n",
       "                      [-1.2225e-01, -4.9385e-02, -1.6284e-02],\n",
       "                      [-4.1035e-02, -1.7143e-02, -5.3444e-02],\n",
       "                      [ 9.5975e-02,  6.5182e-02, -3.8890e-03],\n",
       "                      [-6.4281e-02, -1.0750e-01, -8.3263e-02],\n",
       "                      [-6.0155e-02,  1.0826e-01,  9.4696e-03],\n",
       "                      [-5.9085e-02, -2.0836e-02, -1.4774e-03],\n",
       "                      [ 3.6771e-02,  4.7200e-02,  8.4904e-02],\n",
       "                      [-4.9106e-02, -1.4171e-02, -9.4139e-02],\n",
       "                      [-3.2341e-02, -1.2220e-01,  1.9055e-03],\n",
       "                      [-7.0946e-02, -3.7879e-02,  1.2140e-01],\n",
       "                      [ 1.2236e-01,  2.5469e-02,  7.2808e-02],\n",
       "                      [ 8.9594e-02, -2.5838e-03,  3.3336e-02],\n",
       "                      [-2.6905e-03, -9.2381e-02,  1.0515e-01],\n",
       "                      [-8.8848e-02, -3.4029e-02, -1.0032e-01],\n",
       "                      [-6.6704e-02,  1.3155e-01, -4.2927e-03],\n",
       "                      [ 4.5795e-02,  3.6782e-02,  1.0418e-01],\n",
       "                      [ 3.9383e-02,  1.7083e-02, -4.4113e-02],\n",
       "                      [ 3.6322e-02,  1.7523e-02, -7.2620e-02],\n",
       "                      [-7.6976e-02, -4.0869e-02,  1.2098e-01],\n",
       "                      [ 4.2381e-02,  6.2513e-02,  7.6280e-02],\n",
       "                      [ 1.2293e-02, -9.6458e-02,  1.2646e-01],\n",
       "                      [ 3.4052e-02, -3.1911e-02,  6.3654e-02],\n",
       "                      [-9.4338e-02, -8.4210e-03,  1.0451e-01],\n",
       "                      [ 5.4409e-02, -1.2885e-01,  1.2252e-01],\n",
       "                      [ 2.6338e-02, -3.0251e-02,  9.7937e-02],\n",
       "                      [ 6.9162e-02,  7.2883e-02,  7.4804e-02],\n",
       "                      [-6.5227e-02, -9.9413e-02,  9.5387e-02],\n",
       "                      [ 5.4548e-03,  9.2216e-02,  7.5295e-02],\n",
       "                      [-1.0916e-01,  5.8177e-02,  7.3643e-02],\n",
       "                      [-1.1485e-01,  1.5705e-03, -9.4423e-02],\n",
       "                      [ 7.4762e-02,  7.6024e-02,  5.1604e-02],\n",
       "                      [ 9.0098e-02, -7.6193e-02,  7.4333e-03],\n",
       "                      [-2.9252e-02,  9.0075e-02,  9.3976e-02],\n",
       "                      [-3.1293e-02, -1.1860e-01,  8.5419e-03],\n",
       "                      [ 1.0536e-01, -1.5744e-02,  5.1717e-02],\n",
       "                      [-8.6716e-02, -7.9311e-02, -1.0317e-01],\n",
       "                      [-1.0595e-01, -4.0212e-02, -5.2461e-02],\n",
       "                      [ 6.1244e-02,  9.1080e-02,  2.8326e-02],\n",
       "                      [ 6.3711e-02, -8.2495e-02, -4.0807e-02],\n",
       "                      [-1.0367e-01,  1.2870e-01,  2.6467e-02],\n",
       "                      [-2.1215e-02, -1.1833e-01,  3.6496e-02],\n",
       "                      [-1.1425e-01,  9.0984e-02, -1.0892e-01],\n",
       "                      [ 4.0108e-02,  6.5128e-02, -8.7639e-02],\n",
       "                      [ 9.7802e-02,  1.1197e-01,  9.3300e-02],\n",
       "                      [ 1.2667e-01, -7.1302e-02, -8.7666e-03],\n",
       "                      [ 1.0279e-01,  6.8716e-02, -9.4222e-02],\n",
       "                      [ 1.3594e-01, -1.7022e-02, -2.7824e-02],\n",
       "                      [ 1.7198e-02,  1.3231e-01, -6.3239e-02],\n",
       "                      [ 2.4247e-02, -2.6664e-02, -2.4146e-02],\n",
       "                      [ 5.8000e-02,  8.5480e-03, -1.0218e-01],\n",
       "                      [ 7.7290e-03,  8.2690e-02, -4.8665e-02],\n",
       "                      [ 1.1765e-01, -1.0970e-01,  4.8997e-02],\n",
       "                      [ 9.0677e-02,  3.1362e-02,  6.2543e-02],\n",
       "                      [ 3.1701e-02, -3.1075e-02,  1.0291e-01],\n",
       "                      [-2.1803e-02,  1.0126e-01,  1.2526e-01],\n",
       "                      [-1.0031e-01,  9.1437e-02,  3.8886e-02],\n",
       "                      [-7.1765e-02, -7.3269e-02, -3.7246e-03],\n",
       "                      [ 1.2961e-01,  7.8126e-02, -2.0455e-02],\n",
       "                      [-6.3665e-02, -9.2309e-02, -5.2367e-02],\n",
       "                      [ 1.0475e-02, -1.2002e-01, -9.8262e-02],\n",
       "                      [-6.5396e-02,  4.3753e-02,  5.7489e-02],\n",
       "                      [ 4.9904e-02,  9.1150e-02,  4.3305e-02],\n",
       "                      [-3.5088e-02,  4.1658e-02, -4.4851e-02],\n",
       "                      [ 1.0696e-01, -4.4881e-02, -8.2281e-02],\n",
       "                      [-2.1355e-02, -6.6289e-02, -1.0026e-02],\n",
       "                      [-7.4599e-03,  1.5989e-03, -3.1129e-03],\n",
       "                      [-7.8978e-02, -1.2416e-01, -8.2406e-02],\n",
       "                      [-1.0681e-01, -1.3679e-01,  1.3253e-01],\n",
       "                      [ 8.2697e-02,  4.7246e-02,  9.0025e-02],\n",
       "                      [ 4.9928e-02, -4.5225e-02, -3.5807e-03],\n",
       "                      [-4.4950e-02,  6.3125e-02,  3.8732e-02],\n",
       "                      [-9.1828e-02,  2.6635e-02, -8.3065e-02],\n",
       "                      [ 1.0659e-01,  1.6795e-03,  1.0686e-02],\n",
       "                      [-6.9225e-02,  1.9022e-02,  2.0404e-02],\n",
       "                      [ 4.1211e-02, -9.6589e-02, -4.3589e-02],\n",
       "                      [-7.8389e-02, -8.4695e-02, -5.9993e-02],\n",
       "                      [-9.5095e-02,  1.1806e-01, -1.1268e-01],\n",
       "                      [-2.8879e-02, -2.0088e-03, -4.6624e-02],\n",
       "                      [-2.7298e-02,  4.9410e-02, -2.1421e-02],\n",
       "                      [-8.0539e-03,  1.0765e-01, -3.8316e-02],\n",
       "                      [ 7.8876e-03,  6.6941e-02, -1.5893e-02],\n",
       "                      [-8.6281e-02,  9.5771e-02, -9.4286e-02],\n",
       "                      [-1.0961e-01, -6.8804e-02,  3.0183e-02],\n",
       "                      [ 9.4037e-02, -1.0524e-01, -6.9457e-02],\n",
       "                      [ 1.2633e-01,  8.4511e-02,  6.0754e-02],\n",
       "                      [-9.2299e-02,  5.5812e-02,  5.5772e-03],\n",
       "                      [-8.7880e-02,  1.0971e-01, -7.7962e-02],\n",
       "                      [ 3.3617e-02, -5.6193e-02,  1.1924e-01],\n",
       "                      [ 3.7364e-03, -1.9506e-02,  7.0104e-02],\n",
       "                      [ 1.2708e-01, -7.9599e-03,  9.8146e-02],\n",
       "                      [-3.4696e-02, -5.9566e-02, -5.7383e-02],\n",
       "                      [-1.0716e-01,  9.7819e-02,  4.3793e-02],\n",
       "                      [-7.7002e-02, -9.5948e-02,  8.9644e-02],\n",
       "                      [ 1.1335e-02, -8.3594e-02, -7.1417e-03],\n",
       "                      [-3.2048e-02,  2.8399e-02, -3.8272e-02],\n",
       "                      [-4.6766e-02, -7.1043e-02, -3.9949e-02],\n",
       "                      [-3.2489e-03,  6.5726e-02,  2.1402e-02],\n",
       "                      [ 9.2328e-02, -4.9697e-02, -3.0414e-02],\n",
       "                      [-8.7153e-02, -9.5745e-02, -8.8726e-02],\n",
       "                      [-2.2030e-02,  1.1482e-01, -1.1787e-01],\n",
       "                      [ 1.0583e-01,  5.2139e-02,  7.4517e-02],\n",
       "                      [ 5.3613e-02,  5.4872e-02,  9.5305e-02],\n",
       "                      [ 3.3328e-02, -1.9991e-02,  3.4578e-02],\n",
       "                      [-2.2013e-02, -7.1933e-02,  3.3082e-02],\n",
       "                      [ 1.3771e-01,  8.1900e-02, -4.1131e-02],\n",
       "                      [-2.7368e-03,  4.1003e-02,  7.7617e-02],\n",
       "                      [-9.5872e-02,  4.7485e-03, -1.7963e-03],\n",
       "                      [ 1.2589e-01,  3.0295e-02, -5.0202e-02],\n",
       "                      [-5.2744e-02,  1.1373e-01, -4.9898e-02],\n",
       "                      [ 3.3263e-02,  9.9758e-02, -1.0044e-01],\n",
       "                      [-2.2726e-02, -1.0005e-01, -5.0462e-02],\n",
       "                      [ 5.7880e-02,  1.1866e-02,  7.3963e-02],\n",
       "                      [-9.7312e-02,  6.4726e-02, -6.6611e-02],\n",
       "                      [ 8.0774e-02, -3.4293e-02,  1.0201e-01],\n",
       "                      [-5.7406e-04,  3.2419e-02, -1.0503e-01],\n",
       "                      [ 1.1813e-02,  9.8966e-02, -1.0196e-01],\n",
       "                      [ 7.9490e-02,  3.8079e-02, -6.6201e-02],\n",
       "                      [-6.8410e-02,  6.4509e-02, -2.4905e-02],\n",
       "                      [ 6.6656e-02,  9.9038e-03,  1.2231e-01],\n",
       "                      [-9.3893e-02, -4.9848e-03,  4.7035e-02],\n",
       "                      [-7.4272e-02, -2.2884e-02, -4.0230e-02],\n",
       "                      [ 1.3496e-01,  4.2882e-02, -1.0355e-01],\n",
       "                      [ 2.4167e-02,  9.6320e-02,  5.2407e-02],\n",
       "                      [ 1.2667e-01, -2.2368e-02,  2.5531e-02],\n",
       "                      [ 1.3501e-01,  1.0396e-01, -2.3852e-02],\n",
       "                      [ 3.9122e-02, -7.6825e-03,  1.2310e-01],\n",
       "                      [-6.8002e-02, -3.7916e-03,  3.2622e-02],\n",
       "                      [-2.3719e-02, -6.8379e-02,  1.0211e-01],\n",
       "                      [-4.9025e-02,  7.1428e-02, -3.0695e-02],\n",
       "                      [-1.1000e-01, -9.9183e-02,  4.5333e-02],\n",
       "                      [ 9.7599e-02, -2.4106e-02,  8.9333e-02],\n",
       "                      [ 1.0947e-02,  6.5165e-02,  1.1174e-01],\n",
       "                      [ 7.5833e-02,  1.0602e-01, -8.8843e-02],\n",
       "                      [-1.0356e-01,  8.7951e-02,  1.0390e-01],\n",
       "                      [ 6.9732e-02,  5.8410e-02, -2.2573e-02],\n",
       "                      [ 3.0836e-02, -4.7435e-02, -1.8230e-02],\n",
       "                      [ 1.2929e-01, -8.8485e-02, -9.2712e-02],\n",
       "                      [-1.4283e-02,  5.9550e-02, -1.2061e-01],\n",
       "                      [ 8.8647e-02, -3.1539e-03,  2.4097e-02],\n",
       "                      [ 6.8877e-02,  5.1793e-02, -1.5424e-02],\n",
       "                      [-1.2454e-01,  1.0174e-01, -4.5958e-02],\n",
       "                      [-6.5590e-02,  3.6665e-02,  8.7708e-02],\n",
       "                      [ 1.0558e-02, -6.3433e-02, -1.2068e-01],\n",
       "                      [ 6.1042e-02,  3.4923e-02,  8.0769e-02],\n",
       "                      [ 1.3744e-01, -7.9819e-02,  5.1706e-02],\n",
       "                      [ 1.3728e-01, -1.4836e-02, -3.3132e-02],\n",
       "                      [-1.1080e-01,  9.1621e-03, -7.6355e-02],\n",
       "                      [-7.7563e-02, -1.1133e-01,  5.9121e-02],\n",
       "                      [-3.1088e-02,  5.6880e-02,  5.3864e-02],\n",
       "                      [-1.1107e-01, -4.4440e-02,  1.2455e-01],\n",
       "                      [-8.5523e-03,  7.7339e-02, -9.5051e-02],\n",
       "                      [ 1.2710e-01,  4.6573e-02, -7.4914e-02],\n",
       "                      [ 2.9110e-02,  8.0765e-02,  6.7014e-02],\n",
       "                      [ 3.7749e-02, -3.5271e-02, -2.5622e-02],\n",
       "                      [-9.1845e-02,  1.1274e-01,  2.1583e-02],\n",
       "                      [ 4.0274e-02, -5.9424e-02, -8.4447e-02],\n",
       "                      [-3.3653e-03,  5.4107e-02,  1.0541e-01],\n",
       "                      [-6.8494e-03,  4.6976e-02, -1.6726e-02],\n",
       "                      [-2.3523e-02,  1.1188e-01,  4.4045e-02],\n",
       "                      [ 1.3453e-01, -1.3437e-01,  2.1565e-02],\n",
       "                      [-3.9344e-02,  9.1558e-02,  6.6933e-02],\n",
       "                      [ 3.3610e-02,  6.4725e-02, -6.1314e-02],\n",
       "                      [-1.9988e-02,  7.5388e-02, -5.9920e-02],\n",
       "                      [ 3.4929e-02,  3.6876e-02, -1.0369e-01],\n",
       "                      [-6.0113e-02, -8.0240e-02, -1.0094e-01],\n",
       "                      [-3.1279e-02,  2.6642e-02,  5.9554e-02],\n",
       "                      [ 8.4217e-02,  2.7814e-03, -6.6609e-02],\n",
       "                      [-1.0473e-01,  1.2155e-01,  3.5402e-02],\n",
       "                      [ 1.0890e-01, -1.0438e-01, -5.4910e-02],\n",
       "                      [ 5.2266e-03,  1.1187e-01, -9.4156e-02],\n",
       "                      [-5.3069e-02, -1.0774e-01,  7.6979e-02],\n",
       "                      [ 1.5636e-02, -4.3689e-02,  8.9266e-02],\n",
       "                      [-7.9798e-02, -2.4958e-02, -4.4044e-02],\n",
       "                      [-3.7422e-02,  5.9880e-03, -1.2415e-02],\n",
       "                      [ 1.3659e-01, -9.8087e-02, -3.9585e-02],\n",
       "                      [ 1.4336e-03, -4.0075e-02,  1.2951e-01],\n",
       "                      [ 7.7086e-02,  1.0662e-01,  1.0458e-01],\n",
       "                      [-6.4883e-03,  8.2115e-02, -1.0686e-02],\n",
       "                      [ 1.0068e-01,  2.9520e-02,  6.0330e-02],\n",
       "                      [ 5.8050e-02, -4.4703e-02,  1.1348e-01],\n",
       "                      [ 1.1502e-01, -2.9890e-02, -2.3862e-02],\n",
       "                      [-9.7576e-02,  5.7850e-02, -8.2463e-02],\n",
       "                      [-1.0961e-01,  1.0861e-01,  3.3258e-02],\n",
       "                      [ 1.1672e-01, -1.1747e-01, -6.2750e-02],\n",
       "                      [-2.0043e-02,  9.0033e-02, -8.1558e-02],\n",
       "                      [-9.4951e-02, -4.8779e-02, -5.1929e-02],\n",
       "                      [ 1.3191e-01,  5.3010e-02, -7.3631e-02],\n",
       "                      [-4.0595e-02,  7.2126e-03, -6.4946e-02],\n",
       "                      [-8.1402e-02,  1.2486e-01, -7.0031e-02],\n",
       "                      [ 8.5218e-02, -2.3302e-02, -8.1937e-02],\n",
       "                      [-4.3192e-02, -7.0172e-02, -7.1355e-02],\n",
       "                      [-8.0795e-02, -1.0423e-02, -7.0037e-02],\n",
       "                      [ 1.0447e-01, -1.1662e-01, -1.8019e-02],\n",
       "                      [ 9.5731e-02, -9.5642e-02, -1.5150e-02],\n",
       "                      [-9.3843e-02, -1.1198e-01,  6.7063e-02],\n",
       "                      [ 2.9323e-02,  1.6109e-04,  9.2045e-02],\n",
       "                      [ 6.4272e-03, -1.1339e-01, -1.1192e-01],\n",
       "                      [ 3.0190e-02, -8.5232e-02,  1.2892e-01],\n",
       "                      [-9.2072e-03,  1.1430e-01, -1.3563e-02],\n",
       "                      [-4.4705e-02, -1.1814e-01,  1.3234e-01],\n",
       "                      [-9.5433e-02,  7.5989e-02, -3.5884e-02],\n",
       "                      [-8.7717e-02, -3.8155e-02,  6.4846e-02],\n",
       "                      [ 1.0453e-01, -9.5534e-02, -8.4003e-02],\n",
       "                      [ 5.1153e-02,  5.1652e-02, -7.2032e-02],\n",
       "                      [ 5.7778e-02, -1.6456e-02, -1.0357e-01],\n",
       "                      [ 7.3788e-02, -1.0144e-01, -3.6634e-03],\n",
       "                      [-1.9703e-02, -5.0691e-02, -1.3006e-02],\n",
       "                      [-1.0492e-01,  1.1699e-01, -8.7049e-02],\n",
       "                      [ 9.0454e-02,  1.6411e-02,  7.7366e-03],\n",
       "                      [ 4.3030e-03, -6.3503e-02, -9.2016e-03],\n",
       "                      [ 1.0345e-01, -4.6269e-02,  7.0530e-02],\n",
       "                      [-1.0816e-01, -6.9469e-02,  7.9236e-02],\n",
       "                      [ 5.9203e-02, -1.2643e-01, -7.3999e-02],\n",
       "                      [ 9.4403e-02,  4.0514e-03,  1.2950e-01],\n",
       "                      [-1.2374e-01,  2.0392e-02, -1.2857e-01],\n",
       "                      [ 6.5247e-02, -3.9249e-02,  1.2677e-04]], device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l0_reverse',\n",
       "              tensor([[-0.0161,  0.0158, -0.0770,  ..., -0.0374, -0.0511,  0.0653],\n",
       "                      [-0.1010,  0.0894,  0.0725,  ..., -0.0742, -0.0107,  0.0578],\n",
       "                      [-0.1207, -0.0131, -0.0195,  ...,  0.1267,  0.0255, -0.0027],\n",
       "                      ...,\n",
       "                      [ 0.1263,  0.0624,  0.0109,  ...,  0.1056,  0.0600,  0.1307],\n",
       "                      [ 0.0692,  0.0491,  0.0709,  ...,  0.0617,  0.0596,  0.0223],\n",
       "                      [ 0.1251, -0.0717,  0.0996,  ...,  0.1237, -0.0271, -0.0958]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l0_reverse',\n",
       "              tensor([-0.0576, -0.1108,  0.0612, -0.0446, -0.0090, -0.0625, -0.0192,  0.1354,\n",
       "                       0.0361, -0.0419,  0.1055, -0.0711,  0.0269, -0.0790,  0.0120, -0.0773,\n",
       "                       0.0843, -0.0102,  0.0298, -0.0708,  0.1300,  0.1087,  0.0985, -0.1219,\n",
       "                      -0.1115, -0.0801,  0.0721,  0.0725,  0.0535, -0.0830,  0.0814, -0.0999,\n",
       "                      -0.1052, -0.0423,  0.0800, -0.0687,  0.0873,  0.0756,  0.0741, -0.1209,\n",
       "                      -0.0173, -0.1104, -0.0192,  0.0840, -0.0088,  0.1344,  0.1181, -0.0154,\n",
       "                       0.0274,  0.0844,  0.0084, -0.0078,  0.1025, -0.0926, -0.0460, -0.0185,\n",
       "                       0.1334, -0.1009, -0.0661, -0.0620, -0.0253, -0.0984, -0.0869,  0.0317,\n",
       "                       0.0980,  0.0354,  0.0281,  0.1163,  0.0113,  0.0709,  0.0384, -0.0515,\n",
       "                       0.0827,  0.0318,  0.0003,  0.1020,  0.0635,  0.0545, -0.0563,  0.0111,\n",
       "                      -0.0565, -0.0291, -0.0286,  0.0268,  0.0175,  0.0317, -0.0831, -0.0257,\n",
       "                       0.0002,  0.0949, -0.0365,  0.0780,  0.0219,  0.1182, -0.1074,  0.0823,\n",
       "                      -0.0271, -0.0592, -0.0753,  0.0079,  0.0421, -0.0451, -0.0192, -0.0140,\n",
       "                      -0.0450,  0.0071,  0.1024, -0.1029, -0.0577,  0.0527, -0.0535,  0.0176,\n",
       "                       0.1300, -0.0839, -0.1106,  0.0527,  0.1296, -0.0978,  0.1064, -0.0267,\n",
       "                      -0.0383,  0.0839,  0.1340,  0.0149, -0.0326, -0.0313, -0.0265, -0.1073,\n",
       "                       0.0259,  0.0658, -0.0032,  0.0364,  0.0587,  0.0621,  0.0369,  0.0967,\n",
       "                      -0.0889,  0.0584,  0.0403, -0.1003,  0.0725, -0.1155, -0.0809, -0.0762,\n",
       "                      -0.0284,  0.0761, -0.0093,  0.0558, -0.0857, -0.0534, -0.1217,  0.0823,\n",
       "                      -0.0960, -0.1139, -0.0867, -0.1210, -0.0771,  0.0687,  0.0539, -0.0989,\n",
       "                       0.0446,  0.0601, -0.0130,  0.1235,  0.1357,  0.1233, -0.1290,  0.0363,\n",
       "                      -0.1267, -0.0647,  0.1138, -0.0262, -0.1248, -0.0479,  0.0904, -0.1015,\n",
       "                       0.1026, -0.0613,  0.0852,  0.0011,  0.0540,  0.1110, -0.0821,  0.0985,\n",
       "                       0.0330, -0.0175, -0.1007,  0.0159,  0.0392,  0.1146,  0.0493,  0.0815,\n",
       "                      -0.1135, -0.1033,  0.0107, -0.1034, -0.0091, -0.0810,  0.0694, -0.0911,\n",
       "                      -0.0640,  0.0948, -0.0496, -0.0824,  0.0882,  0.1340,  0.0403, -0.0300,\n",
       "                      -0.0455, -0.0783,  0.0318,  0.0063,  0.0019, -0.0820,  0.1260, -0.0811,\n",
       "                      -0.0443,  0.1201,  0.0163,  0.0133,  0.0756,  0.0176,  0.0008,  0.0575,\n",
       "                       0.0556, -0.0823,  0.0364, -0.0381,  0.1268,  0.0497,  0.0513,  0.1054,\n",
       "                      -0.0212,  0.0797, -0.1070,  0.0583,  0.1074, -0.0479, -0.0141,  0.0345,\n",
       "                      -0.0416, -0.0844, -0.0568, -0.0963,  0.0430, -0.0320,  0.1135, -0.0694,\n",
       "                       0.1018, -0.0418, -0.1104,  0.0373, -0.0465, -0.0749, -0.0614, -0.0588],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l0_reverse',\n",
       "              tensor([-0.0196,  0.0565,  0.0350,  0.0727,  0.0815,  0.0301,  0.0085, -0.0959,\n",
       "                       0.0730, -0.0965, -0.0059,  0.0003,  0.0996, -0.0799, -0.0287,  0.0746,\n",
       "                       0.0536,  0.0307,  0.0806,  0.0876,  0.1140,  0.1026,  0.0102,  0.1201,\n",
       "                      -0.0148,  0.0893,  0.0896, -0.0280, -0.0162, -0.0910,  0.0316, -0.0095,\n",
       "                       0.0669,  0.0927,  0.1080, -0.0184,  0.1004, -0.0315, -0.0041, -0.0656,\n",
       "                       0.1127,  0.0127, -0.0134, -0.0398,  0.0908,  0.0107,  0.0834, -0.0814,\n",
       "                      -0.0915, -0.0273,  0.1267, -0.1046,  0.0540, -0.0416,  0.0435, -0.0925,\n",
       "                       0.0766,  0.0305, -0.0802,  0.1002, -0.0271, -0.0085, -0.0939,  0.0578,\n",
       "                       0.0481, -0.0644,  0.1082,  0.0408, -0.0240,  0.0682, -0.0056,  0.0388,\n",
       "                       0.0817, -0.1075,  0.1004,  0.1081,  0.0109, -0.0900,  0.0448,  0.0779,\n",
       "                      -0.0876,  0.1296,  0.0292, -0.0331, -0.0637, -0.1222, -0.0759,  0.0784,\n",
       "                      -0.0371, -0.0738, -0.0048,  0.0969, -0.1023, -0.0131, -0.0057,  0.0314,\n",
       "                      -0.0662,  0.0062,  0.1168, -0.0730,  0.1365,  0.0887, -0.0848, -0.0068,\n",
       "                       0.0719,  0.0094, -0.0617, -0.0583, -0.0073, -0.0707,  0.0005,  0.0616,\n",
       "                       0.0640, -0.0215,  0.0495, -0.0409, -0.0432, -0.0724, -0.0626,  0.0251,\n",
       "                       0.0773,  0.1168,  0.0783,  0.0722,  0.0460, -0.0183,  0.0844, -0.0457,\n",
       "                       0.0693, -0.0318,  0.0097,  0.0646,  0.0824,  0.0067,  0.0894,  0.1331,\n",
       "                       0.0685,  0.0758, -0.0745,  0.0993, -0.0727, -0.0177,  0.0214, -0.0168,\n",
       "                       0.1253, -0.0035,  0.0786,  0.1161,  0.0133, -0.0525,  0.0059, -0.1037,\n",
       "                       0.0277,  0.0474, -0.0250,  0.0247, -0.1170,  0.0873,  0.0274,  0.0164,\n",
       "                      -0.0505,  0.0427, -0.0467,  0.0362, -0.0185,  0.1065,  0.0790, -0.0286,\n",
       "                      -0.0211,  0.1140,  0.0423,  0.0278,  0.1079, -0.0336, -0.0266, -0.0536,\n",
       "                       0.1239,  0.0026,  0.0910, -0.0451, -0.1029,  0.0400, -0.0716,  0.0642,\n",
       "                      -0.0305,  0.1119,  0.0477, -0.0514, -0.1245, -0.1072, -0.0619, -0.0290,\n",
       "                      -0.0660,  0.0696,  0.0641,  0.0447,  0.0514, -0.0357, -0.0636,  0.0770,\n",
       "                      -0.0768, -0.0525,  0.0220,  0.0208, -0.1085,  0.0013,  0.0381,  0.0133,\n",
       "                      -0.0235, -0.0567,  0.0875, -0.0840, -0.0343, -0.0827,  0.0953,  0.0008,\n",
       "                      -0.0307,  0.0706,  0.0849,  0.0732, -0.0883,  0.0266, -0.0527, -0.1096,\n",
       "                       0.1336,  0.0623,  0.0565, -0.0871, -0.0084, -0.0634, -0.0823, -0.1187,\n",
       "                      -0.0274, -0.0031,  0.0811,  0.0702, -0.0443,  0.0446,  0.0332, -0.0892,\n",
       "                       0.0676,  0.0801, -0.0543,  0.0191,  0.0695, -0.1137, -0.1069, -0.1177,\n",
       "                       0.0501, -0.0334,  0.0664,  0.0412, -0.0699, -0.0227,  0.0166,  0.0177],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_ih_l1',\n",
       "              tensor([[-0.0264,  0.0418,  0.0226,  ..., -0.0805,  0.1142, -0.0406],\n",
       "                      [ 0.0137, -0.0964, -0.0394,  ..., -0.0628,  0.0278,  0.0346],\n",
       "                      [-0.0400,  0.0343, -0.0363,  ...,  0.0489, -0.0849, -0.0790],\n",
       "                      ...,\n",
       "                      [ 0.0742,  0.0432, -0.0932,  ...,  0.0312, -0.1151,  0.0509],\n",
       "                      [-0.0511,  0.1102,  0.1022,  ..., -0.0325,  0.0972, -0.0080],\n",
       "                      [ 0.0192,  0.0693,  0.0657,  ..., -0.0583,  0.1092,  0.1089]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l1',\n",
       "              tensor([[ 0.0560,  0.0724, -0.1082,  ..., -0.0292, -0.0509, -0.1287],\n",
       "                      [ 0.0408,  0.1012,  0.0391,  ...,  0.0743, -0.0873,  0.0999],\n",
       "                      [ 0.0113,  0.0460, -0.0630,  ..., -0.1209,  0.0433, -0.0505],\n",
       "                      ...,\n",
       "                      [-0.0515, -0.0655,  0.0357,  ..., -0.1357,  0.0869, -0.0219],\n",
       "                      [ 0.0571,  0.0800, -0.0946,  ...,  0.0215,  0.1072,  0.0201],\n",
       "                      [-0.1290,  0.1069, -0.0117,  ...,  0.0799, -0.1355,  0.1013]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l1',\n",
       "              tensor([ 0.0483,  0.0644, -0.0896,  0.0462, -0.0146,  0.0938, -0.0096, -0.0626,\n",
       "                       0.0013,  0.0829,  0.1257, -0.1087,  0.1242,  0.0620,  0.0079, -0.0944,\n",
       "                      -0.1136,  0.1179,  0.0321,  0.1150, -0.0861, -0.0748, -0.0673,  0.1359,\n",
       "                      -0.1095, -0.1036,  0.0279,  0.0203, -0.0903,  0.0430, -0.0636, -0.0262,\n",
       "                       0.0287,  0.1323,  0.0938,  0.0102,  0.0690, -0.0856,  0.0006, -0.0662,\n",
       "                      -0.0657,  0.0661, -0.0388, -0.0859, -0.1112,  0.0978,  0.0948,  0.1061,\n",
       "                       0.0979,  0.0070, -0.0265,  0.0045,  0.0177,  0.0552,  0.0219, -0.1082,\n",
       "                      -0.0503,  0.0965,  0.1052, -0.0099, -0.0950,  0.1176,  0.0528, -0.0058,\n",
       "                      -0.0098, -0.0560,  0.0790,  0.0801,  0.0097,  0.0218, -0.1157,  0.0048,\n",
       "                      -0.1117,  0.0778,  0.1249,  0.0209, -0.1100, -0.0111,  0.0508, -0.0397,\n",
       "                      -0.0370,  0.0996,  0.0677, -0.0841,  0.0831,  0.0525, -0.0198,  0.0729,\n",
       "                       0.0948,  0.0601, -0.0859, -0.1132,  0.1213, -0.1018, -0.0600,  0.0721,\n",
       "                      -0.0438, -0.0997, -0.0508,  0.1064, -0.0686, -0.1014,  0.0523, -0.0670,\n",
       "                       0.0393,  0.0787, -0.0422, -0.0526,  0.0868, -0.0737, -0.0997, -0.0783,\n",
       "                      -0.0524, -0.0337,  0.1030,  0.0713,  0.1342,  0.0808,  0.0104,  0.0102,\n",
       "                      -0.0617,  0.0582, -0.0759, -0.1100, -0.0368,  0.0367,  0.0216,  0.0455,\n",
       "                       0.0202, -0.1115, -0.0520, -0.0149, -0.0853,  0.0604, -0.0367, -0.0631,\n",
       "                      -0.0306, -0.0662,  0.0503,  0.0257, -0.0559, -0.0431,  0.1283, -0.0239,\n",
       "                       0.0110, -0.0045, -0.0729, -0.0982, -0.1223,  0.0374, -0.0002, -0.0851,\n",
       "                      -0.0828, -0.0478, -0.0893,  0.1054, -0.0296, -0.0358, -0.1023,  0.0034,\n",
       "                      -0.1099,  0.0427, -0.0652, -0.0374,  0.0953,  0.0514, -0.0046,  0.0576,\n",
       "                      -0.0460,  0.0543,  0.0641, -0.0562,  0.0572, -0.0984, -0.0338, -0.1151,\n",
       "                      -0.1028,  0.1123,  0.1113, -0.0260, -0.0084, -0.0366,  0.0620, -0.0370,\n",
       "                       0.0679, -0.0669, -0.1087, -0.0560,  0.1065, -0.1280, -0.1316,  0.0080,\n",
       "                      -0.0252,  0.0433,  0.0031,  0.0628,  0.0564, -0.0094, -0.0433, -0.0827,\n",
       "                      -0.0437,  0.1066,  0.0677, -0.0772,  0.0220, -0.1169,  0.0968,  0.1055,\n",
       "                       0.0907,  0.1118,  0.0451,  0.1047,  0.1144, -0.0826,  0.0901,  0.0679,\n",
       "                       0.0492,  0.0654,  0.0915,  0.0053, -0.0213, -0.0404,  0.1241, -0.0804,\n",
       "                       0.0806,  0.0555, -0.0048, -0.0999, -0.0610, -0.1104,  0.0434,  0.0639,\n",
       "                      -0.0281,  0.0530,  0.1295, -0.0303, -0.0295,  0.1182,  0.0262, -0.0262,\n",
       "                      -0.0577, -0.0236,  0.0097,  0.0196,  0.0802,  0.0079, -0.0891, -0.0765,\n",
       "                      -0.0137,  0.0954, -0.0483, -0.0372,  0.0795,  0.0078, -0.0085, -0.0728],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l1',\n",
       "              tensor([-0.0136,  0.0199,  0.1004,  0.0654, -0.0463,  0.0036, -0.0517, -0.0284,\n",
       "                       0.1042, -0.0367, -0.0969,  0.0604, -0.0789, -0.0077, -0.0573,  0.0440,\n",
       "                       0.0345,  0.0561,  0.1089,  0.1013,  0.1329,  0.1013, -0.0676, -0.0067,\n",
       "                      -0.0041,  0.0164, -0.0228, -0.0967,  0.1321, -0.0750,  0.0064, -0.0556,\n",
       "                       0.0295,  0.0590,  0.0260,  0.0681, -0.0776,  0.0061, -0.1132, -0.1071,\n",
       "                       0.0415,  0.0440, -0.0702,  0.1125,  0.1082,  0.0658, -0.0690, -0.0706,\n",
       "                       0.1154, -0.0977, -0.0270,  0.0990,  0.0195, -0.0749, -0.0698, -0.0823,\n",
       "                      -0.0851,  0.1222,  0.0197,  0.1063, -0.0949, -0.0179, -0.0813,  0.1014,\n",
       "                      -0.0085,  0.0347,  0.0696,  0.0238, -0.0669, -0.0982, -0.0143,  0.1336,\n",
       "                       0.0672,  0.1058, -0.1165, -0.0955,  0.1197, -0.0585, -0.0569,  0.0604,\n",
       "                      -0.0526, -0.0247,  0.1045, -0.1055, -0.0684, -0.0816, -0.0263,  0.0173,\n",
       "                      -0.0014,  0.0615, -0.0697, -0.0346, -0.0923,  0.0472, -0.0471,  0.0711,\n",
       "                      -0.0207, -0.0975,  0.0137,  0.0036,  0.1282,  0.0747, -0.0235,  0.1039,\n",
       "                       0.0399,  0.0080, -0.0829, -0.0732, -0.0341, -0.0494, -0.0196, -0.0938,\n",
       "                       0.0232,  0.0863, -0.0506, -0.0007, -0.1002,  0.0534,  0.1206, -0.0977,\n",
       "                      -0.1138,  0.1220,  0.0479, -0.0639, -0.0797, -0.0633, -0.0327,  0.0944,\n",
       "                      -0.0839, -0.0897,  0.1200, -0.0847, -0.0879,  0.1160,  0.0911, -0.0586,\n",
       "                       0.0752,  0.1347, -0.0650,  0.0860,  0.0149,  0.0460,  0.0462, -0.0503,\n",
       "                       0.0777, -0.1162, -0.0635, -0.0026, -0.0232, -0.0941, -0.0048,  0.0951,\n",
       "                      -0.0573, -0.0535, -0.1201, -0.0355, -0.0977,  0.0729, -0.0055, -0.0727,\n",
       "                      -0.0244, -0.1197,  0.0279,  0.0662,  0.0640, -0.0445,  0.0934,  0.0434,\n",
       "                      -0.1117, -0.0036,  0.0667,  0.1097,  0.0939, -0.1063,  0.0082, -0.0178,\n",
       "                      -0.0066, -0.0466,  0.0281,  0.0324,  0.1046, -0.1238, -0.0986,  0.0739,\n",
       "                      -0.0798, -0.1021,  0.1070, -0.0729,  0.0674,  0.0371, -0.1218, -0.1224,\n",
       "                      -0.0673,  0.0367, -0.0138,  0.0873,  0.0374, -0.0436, -0.0269, -0.0076,\n",
       "                      -0.1016,  0.0410, -0.0488,  0.1110,  0.0078,  0.1180,  0.0320,  0.1298,\n",
       "                       0.0312,  0.1120, -0.0074, -0.0955,  0.1318, -0.0106, -0.0274, -0.0588,\n",
       "                      -0.0686,  0.0586,  0.1080,  0.0692, -0.0778,  0.0802,  0.1198, -0.0871,\n",
       "                       0.0055,  0.1191,  0.0772, -0.0289,  0.1211,  0.1060, -0.1148,  0.0268,\n",
       "                       0.0609, -0.0638,  0.0160, -0.0905, -0.0735,  0.0782, -0.0349,  0.0271,\n",
       "                      -0.0746, -0.0942,  0.0388,  0.0836,  0.0631,  0.0490, -0.0011, -0.0076,\n",
       "                       0.0851,  0.0774, -0.0998, -0.0518,  0.1138,  0.0625, -0.0161,  0.0554],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_ih_l1_reverse',\n",
       "              tensor([[ 0.0062,  0.0292,  0.0222,  ...,  0.0998,  0.0303,  0.0325],\n",
       "                      [ 0.0543,  0.1266,  0.1290,  ..., -0.0344,  0.1228,  0.1204],\n",
       "                      [ 0.0478,  0.1282,  0.0874,  ...,  0.0679, -0.0732,  0.1186],\n",
       "                      ...,\n",
       "                      [ 0.0677,  0.0449,  0.1286,  ...,  0.0531, -0.0020, -0.0793],\n",
       "                      [ 0.0609, -0.0650, -0.0425,  ...,  0.0950,  0.0597, -0.0482],\n",
       "                      [ 0.0761, -0.0621, -0.0328,  ..., -0.0935,  0.0057, -0.0453]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l1_reverse',\n",
       "              tensor([[ 0.0155, -0.0242,  0.0528,  ...,  0.0450, -0.0063,  0.0834],\n",
       "                      [-0.0783, -0.0471, -0.0151,  ...,  0.0426,  0.0113, -0.0291],\n",
       "                      [ 0.0985,  0.0946, -0.0327,  ..., -0.0251,  0.0097, -0.0736],\n",
       "                      ...,\n",
       "                      [ 0.0667,  0.0824,  0.0811,  ...,  0.0701, -0.1108, -0.0542],\n",
       "                      [ 0.0065,  0.0096,  0.0549,  ...,  0.0510, -0.1157, -0.0245],\n",
       "                      [-0.0346, -0.0768,  0.1080,  ...,  0.0534,  0.0317, -0.0171]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l1_reverse',\n",
       "              tensor([ 8.2581e-02,  2.1360e-02, -1.6773e-02,  1.0700e-01,  6.9015e-02,\n",
       "                       6.0285e-02, -8.9684e-03,  3.7603e-02, -8.8424e-02,  1.1586e-01,\n",
       "                      -1.3410e-02,  8.3221e-03,  3.5419e-02, -1.0195e-01,  2.2379e-02,\n",
       "                      -1.4233e-02, -7.1148e-02,  4.8886e-04, -5.7113e-03, -2.7740e-02,\n",
       "                      -4.8899e-02, -7.8282e-02,  8.6178e-02,  5.8439e-02,  1.3217e-01,\n",
       "                      -2.4886e-02,  7.8188e-02,  4.0485e-02, -2.8362e-03,  4.1623e-02,\n",
       "                      -1.1713e-02, -6.4783e-02,  5.2306e-02, -5.7329e-02,  7.6333e-02,\n",
       "                       7.5750e-02,  1.3162e-01, -3.7324e-02, -2.7309e-02,  4.5410e-02,\n",
       "                      -1.7447e-02, -4.7027e-02,  7.7290e-02, -7.9316e-03,  2.5768e-02,\n",
       "                       7.5183e-02,  5.3583e-02,  4.8507e-03,  7.9744e-03, -8.9003e-02,\n",
       "                       6.1258e-02, -3.4359e-02,  1.2885e-01,  1.3240e-01, -1.1680e-01,\n",
       "                       5.4491e-02,  5.3742e-02,  6.8849e-02,  6.9769e-02, -9.9136e-02,\n",
       "                      -8.7648e-02, -4.8082e-02, -1.3884e-02, -1.5132e-02,  4.1721e-02,\n",
       "                      -9.4479e-02,  8.1017e-02,  4.6558e-02,  7.9247e-03,  3.6621e-02,\n",
       "                      -1.8213e-02,  5.6265e-02,  3.1000e-02, -9.0693e-02,  7.8617e-02,\n",
       "                       5.6508e-03, -1.7033e-02, -9.8684e-03, -9.4784e-03,  1.1282e-01,\n",
       "                       1.2762e-01,  4.4349e-02, -7.4039e-02,  5.1345e-02,  8.3910e-02,\n",
       "                      -1.9576e-02, -1.0830e-01, -2.6108e-02, -7.1237e-02, -2.5403e-02,\n",
       "                       2.7938e-02, -6.1547e-03,  1.3103e-01,  7.9758e-02, -1.6652e-02,\n",
       "                       1.1901e-01,  3.2189e-02,  8.5783e-02, -1.1300e-02, -1.1160e-01,\n",
       "                       9.8964e-02,  2.8544e-03,  1.1644e-02,  8.9486e-03,  5.9435e-03,\n",
       "                       5.7576e-02,  3.3766e-02, -8.3633e-02,  1.2493e-01, -2.1107e-02,\n",
       "                      -9.3491e-02,  1.2609e-01,  8.6456e-02, -1.0933e-02,  2.6202e-02,\n",
       "                       1.9829e-02,  5.3152e-02, -2.4016e-02,  3.3018e-02,  1.0623e-01,\n",
       "                       6.5349e-03, -2.4104e-02,  5.5153e-03,  2.7840e-02, -8.1931e-02,\n",
       "                       1.7676e-02, -5.1211e-02, -8.3678e-02, -7.9604e-02, -5.9954e-02,\n",
       "                       3.3226e-02,  5.1858e-02,  3.0157e-02,  9.8169e-02,  1.9957e-02,\n",
       "                      -8.2434e-02, -3.2861e-02,  9.2786e-03, -9.0091e-02,  6.9930e-02,\n",
       "                       9.5883e-02,  4.2409e-03, -1.2615e-01, -9.3043e-02, -1.3018e-01,\n",
       "                       5.5482e-02,  8.9114e-02,  5.9370e-02, -4.0359e-02, -7.8654e-02,\n",
       "                       1.7286e-02,  6.8431e-03,  5.9212e-02,  1.2226e-01, -9.2401e-02,\n",
       "                      -3.7319e-02, -8.6023e-02,  1.0706e-01, -5.7891e-02,  1.9510e-02,\n",
       "                      -1.0895e-01, -1.8942e-02, -1.3063e-01,  1.8240e-02, -5.9411e-03,\n",
       "                       4.1675e-02,  3.4807e-02,  5.7455e-03, -9.0961e-02, -1.7974e-02,\n",
       "                      -5.7856e-03,  9.7296e-02,  3.3286e-02,  6.6325e-02,  1.3623e-01,\n",
       "                      -9.4860e-02, -1.1457e-01,  6.5302e-03, -5.3105e-02, -1.6375e-03,\n",
       "                       2.8099e-02,  5.8736e-02,  4.1609e-02,  1.3182e-01,  9.0085e-02,\n",
       "                      -2.3833e-02, -6.2375e-02,  2.6137e-02, -5.7950e-02, -6.5145e-02,\n",
       "                       5.3744e-03,  1.0243e-01, -1.6444e-02,  1.2471e-01,  7.0919e-03,\n",
       "                       2.6722e-02,  1.8300e-02, -9.1360e-03,  6.8892e-02, -5.0472e-02,\n",
       "                       1.3901e-02,  1.7616e-02,  3.5801e-02,  1.1119e-01, -6.6966e-02,\n",
       "                      -1.0968e-01,  3.7811e-02,  5.0059e-02, -2.1103e-02,  3.4654e-02,\n",
       "                       9.3064e-02, -6.4759e-02, -7.7172e-03,  3.3718e-02, -1.0060e-01,\n",
       "                      -1.0500e-01,  8.5861e-03, -9.0878e-02, -2.4722e-02,  4.4284e-02,\n",
       "                       3.8699e-02,  8.3427e-02,  5.2606e-02,  1.0474e-01,  1.3563e-01,\n",
       "                      -6.2124e-02, -2.8207e-02, -2.4127e-02, -6.6473e-02,  7.4056e-02,\n",
       "                      -5.9321e-02, -2.6596e-02, -2.8550e-02, -4.8046e-02, -2.9534e-02,\n",
       "                       9.1598e-02,  5.5598e-06,  8.8440e-02, -3.8930e-02,  4.5501e-03,\n",
       "                       1.0450e-02, -1.0647e-01, -1.7261e-02, -3.2907e-02,  8.8790e-02,\n",
       "                      -1.1317e-01, -9.2216e-02,  8.4518e-02,  4.5640e-03, -4.2353e-02,\n",
       "                      -1.2496e-02,  5.2491e-02, -4.7906e-02, -5.6162e-02, -1.0668e-01,\n",
       "                      -7.1710e-02], device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l1_reverse',\n",
       "              tensor([-0.0071,  0.0385,  0.0950,  0.0732,  0.0349,  0.0605, -0.0907, -0.0676,\n",
       "                      -0.0820,  0.1359, -0.0774,  0.0468,  0.0382,  0.1221,  0.0072,  0.0739,\n",
       "                      -0.0327, -0.0394,  0.1173,  0.0645, -0.0938,  0.0504, -0.0409,  0.1332,\n",
       "                      -0.0704, -0.0222,  0.0625, -0.0349, -0.0803,  0.1156, -0.0401, -0.0179,\n",
       "                      -0.0407,  0.0810,  0.0616,  0.1238, -0.0106, -0.0862,  0.1198,  0.1068,\n",
       "                       0.0751, -0.0032, -0.0705,  0.0208,  0.0961,  0.0408,  0.1029,  0.0098,\n",
       "                      -0.0558, -0.0937, -0.0211, -0.0305, -0.0244,  0.0630,  0.0459,  0.0910,\n",
       "                      -0.0311,  0.0121,  0.1043,  0.0866, -0.0100, -0.0116, -0.1050, -0.1061,\n",
       "                      -0.0266,  0.0695,  0.0785,  0.0848, -0.0683,  0.0733,  0.0463, -0.0664,\n",
       "                      -0.0664,  0.1123,  0.0905, -0.0693, -0.0508, -0.0527, -0.0503,  0.0673,\n",
       "                       0.0558, -0.0499, -0.0031,  0.1041,  0.0391,  0.0351,  0.0572, -0.0159,\n",
       "                       0.0599, -0.0866, -0.0847,  0.1186,  0.0276,  0.0365, -0.0160, -0.0488,\n",
       "                       0.1267,  0.0589,  0.0949, -0.0858, -0.0913,  0.0834, -0.0272, -0.0123,\n",
       "                       0.1124,  0.0917,  0.1140, -0.0453,  0.0698, -0.0240,  0.0699, -0.1146,\n",
       "                       0.1312, -0.0836,  0.0547,  0.0253, -0.0179,  0.1263,  0.0312,  0.0654,\n",
       "                      -0.0487,  0.0655,  0.0413,  0.0205, -0.0757,  0.0849,  0.0497, -0.0978,\n",
       "                      -0.0435, -0.1262, -0.1147, -0.0922,  0.1245, -0.0275,  0.0271, -0.1159,\n",
       "                       0.0969,  0.1083, -0.0002,  0.0290, -0.1070, -0.0051, -0.0264, -0.1303,\n",
       "                       0.0216, -0.0885,  0.1079, -0.1022, -0.1186,  0.0143,  0.0098, -0.1280,\n",
       "                       0.0283,  0.0805, -0.0381, -0.1077,  0.0563, -0.0592, -0.1129,  0.0773,\n",
       "                       0.0511, -0.0139, -0.0859, -0.0456, -0.0871,  0.1076,  0.0421, -0.0322,\n",
       "                      -0.1163,  0.0146, -0.1311, -0.0319, -0.0942,  0.0249, -0.0573,  0.0945,\n",
       "                      -0.0215,  0.0927, -0.0683, -0.1134,  0.1249, -0.0722,  0.0335, -0.0443,\n",
       "                       0.1058, -0.0564,  0.1048, -0.1052,  0.0733, -0.0617,  0.0209,  0.1152,\n",
       "                       0.0049, -0.0555,  0.1157, -0.1036, -0.0473, -0.0826, -0.0950, -0.0453,\n",
       "                       0.0373, -0.0046, -0.0029,  0.0785,  0.1183,  0.0854, -0.0457,  0.1289,\n",
       "                      -0.0842,  0.0424,  0.0560,  0.0501,  0.1097, -0.0556, -0.0251, -0.0996,\n",
       "                      -0.0775,  0.0353,  0.1289,  0.0041,  0.0705,  0.0482, -0.0710,  0.0175,\n",
       "                       0.0101,  0.0871, -0.0043,  0.0705,  0.0760,  0.0610, -0.0989, -0.0760,\n",
       "                       0.1302, -0.0826,  0.1153, -0.1131,  0.0103, -0.0165, -0.0933,  0.0164,\n",
       "                       0.0889,  0.0917,  0.0945,  0.1265,  0.0393, -0.0358, -0.0341, -0.0562,\n",
       "                      -0.0642,  0.0468,  0.0696, -0.0395, -0.0688,  0.0449,  0.0401, -0.0644],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_ih_l2',\n",
       "              tensor([[ 0.0920, -0.0035,  0.0867,  ...,  0.0397, -0.0761,  0.0849],\n",
       "                      [-0.0177, -0.0756,  0.1202,  ..., -0.0312,  0.0103,  0.0413],\n",
       "                      [ 0.0583,  0.0585, -0.0456,  ..., -0.1119, -0.0787, -0.0339],\n",
       "                      ...,\n",
       "                      [-0.0653, -0.0734, -0.0910,  ..., -0.0329, -0.0856,  0.0533],\n",
       "                      [-0.0360, -0.0123, -0.0720,  ...,  0.0426,  0.0252,  0.1045],\n",
       "                      [-0.0446,  0.0331, -0.1079,  ...,  0.0607, -0.0197, -0.0263]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l2',\n",
       "              tensor([[ 0.0387,  0.1139,  0.0367,  ...,  0.0428, -0.0108, -0.0008],\n",
       "                      [-0.1033, -0.0182, -0.0500,  ..., -0.0422, -0.0577,  0.0865],\n",
       "                      [ 0.1127, -0.0020,  0.1125,  ..., -0.0880,  0.1030,  0.0421],\n",
       "                      ...,\n",
       "                      [-0.0285,  0.0005, -0.1095,  ..., -0.0963,  0.0199,  0.0762],\n",
       "                      [ 0.0264, -0.0667, -0.1091,  ..., -0.0135,  0.0072,  0.1204],\n",
       "                      [-0.0045,  0.0925, -0.0654,  ..., -0.1101, -0.0516, -0.0141]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l2',\n",
       "              tensor([ 0.0961, -0.0455,  0.0729, -0.0368,  0.0088, -0.0032, -0.0383,  0.0688,\n",
       "                       0.0220,  0.0947, -0.0839, -0.0523, -0.0645, -0.1064, -0.0049, -0.0614,\n",
       "                       0.0115, -0.0901, -0.0582,  0.0226,  0.1131, -0.1003, -0.0473, -0.0407,\n",
       "                       0.1132,  0.0644, -0.0578,  0.1111,  0.0592, -0.0442, -0.0395, -0.0889,\n",
       "                       0.0608, -0.0768,  0.0823,  0.0801,  0.0650,  0.0855,  0.0375,  0.1110,\n",
       "                      -0.0678,  0.0065, -0.0706, -0.0987,  0.1144,  0.0835, -0.0794,  0.1217,\n",
       "                       0.1052,  0.1015,  0.0407, -0.0750,  0.1020,  0.1314, -0.0453, -0.1005,\n",
       "                      -0.0786, -0.0607, -0.1053,  0.0004,  0.0882, -0.0339, -0.0873, -0.0278,\n",
       "                       0.1054,  0.0507,  0.0090,  0.0236, -0.1234, -0.0942,  0.1059, -0.0862,\n",
       "                       0.0661, -0.0811,  0.0899,  0.0456,  0.0008,  0.0186, -0.0223, -0.1057,\n",
       "                      -0.0738,  0.0333,  0.0026, -0.0679,  0.1216, -0.0493,  0.1320,  0.0949,\n",
       "                      -0.0165,  0.1100, -0.1154,  0.0214, -0.0261, -0.0399,  0.1190,  0.1064,\n",
       "                      -0.0531,  0.0519,  0.0726, -0.0044,  0.0203,  0.1047, -0.0652, -0.0253,\n",
       "                       0.0922,  0.0855,  0.0423, -0.0059, -0.0666,  0.1269, -0.0345, -0.0796,\n",
       "                       0.1152, -0.1103, -0.0359, -0.0411, -0.0282, -0.0378, -0.0614, -0.0704,\n",
       "                       0.0693, -0.1014, -0.1081,  0.1214, -0.0572, -0.1133, -0.0619,  0.0649,\n",
       "                      -0.0970,  0.1050,  0.1231, -0.0556, -0.0245,  0.0550, -0.0129,  0.0769,\n",
       "                      -0.1144,  0.1022, -0.0052, -0.0587, -0.0063, -0.0424, -0.0410,  0.0552,\n",
       "                      -0.0203, -0.1184, -0.1349, -0.0916, -0.0720, -0.0935,  0.0681, -0.0667,\n",
       "                       0.1127,  0.0325, -0.0305,  0.0673,  0.1246,  0.0950,  0.0390,  0.0785,\n",
       "                       0.0721,  0.1329,  0.0013, -0.0621,  0.0496,  0.0628,  0.0817, -0.0940,\n",
       "                       0.0382,  0.0830, -0.0274, -0.1264,  0.1244,  0.1162, -0.0557, -0.0172,\n",
       "                       0.0237, -0.0229, -0.1040, -0.0059,  0.0830,  0.0687,  0.0864, -0.0415,\n",
       "                      -0.0102,  0.0828, -0.0052, -0.0212, -0.0021, -0.0947, -0.0305, -0.0389,\n",
       "                       0.0929, -0.0309, -0.0686, -0.0636, -0.0557, -0.0332, -0.0186,  0.0743,\n",
       "                       0.0535,  0.0802, -0.0255, -0.0041,  0.0598,  0.0533,  0.0435,  0.0033,\n",
       "                       0.0350, -0.0088,  0.1046,  0.0984,  0.1064,  0.0039, -0.1115, -0.0660,\n",
       "                       0.0070,  0.0787,  0.1018, -0.0298,  0.1063, -0.0481,  0.1274, -0.0266,\n",
       "                       0.0800,  0.1063,  0.0170,  0.1188,  0.0895, -0.0465,  0.0757, -0.0446,\n",
       "                      -0.0902, -0.0695,  0.0551,  0.0862, -0.0335, -0.0147, -0.0786, -0.0626,\n",
       "                      -0.0911,  0.0250, -0.0814, -0.0603, -0.1103,  0.0741, -0.0161, -0.0023,\n",
       "                      -0.0825,  0.0363,  0.0422,  0.1040, -0.0540,  0.0819, -0.0776,  0.0361],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l2',\n",
       "              tensor([-4.3626e-02, -3.5426e-02, -7.2519e-02,  1.1291e-01,  1.0801e-01,\n",
       "                      -2.9947e-02, -1.0344e-01, -5.4915e-02, -1.2697e-02,  2.8792e-02,\n",
       "                      -3.2245e-03,  5.8630e-03,  4.0123e-02,  8.0097e-02, -1.0322e-01,\n",
       "                      -4.9956e-02, -8.1400e-02,  1.3084e-01,  6.0265e-02,  6.6208e-03,\n",
       "                       7.0188e-03,  7.8089e-02, -3.7322e-02,  7.9710e-03,  3.2550e-03,\n",
       "                      -1.1313e-01,  2.0226e-02, -1.1545e-01,  2.3334e-02, -1.7402e-02,\n",
       "                       8.7549e-02,  6.7557e-02, -5.9155e-02, -5.7971e-02, -8.5149e-02,\n",
       "                      -8.1047e-02,  1.0018e-01,  5.1232e-02, -4.3131e-02, -2.0791e-02,\n",
       "                      -1.6911e-02,  2.8772e-02, -2.2751e-02, -7.8334e-02, -6.3830e-04,\n",
       "                      -9.6166e-02,  5.6699e-02,  9.5516e-02,  9.6647e-02,  4.8610e-02,\n",
       "                       2.9908e-02,  7.2699e-03, -6.9820e-02,  1.1450e-01, -3.9969e-02,\n",
       "                      -4.7101e-02, -6.3964e-02,  1.1239e-01,  8.5400e-02, -3.1422e-02,\n",
       "                       1.2070e-01, -7.4834e-02,  1.2480e-01, -1.9808e-02, -6.3895e-02,\n",
       "                       4.9150e-02,  6.5384e-02,  8.1083e-02,  1.2592e-02,  5.1695e-03,\n",
       "                       3.1281e-03, -7.1820e-02,  1.3396e-02,  5.4416e-02,  1.2633e-01,\n",
       "                      -7.0975e-05, -8.4054e-02, -4.8062e-02,  9.7571e-02,  5.6175e-02,\n",
       "                      -1.1222e-01, -5.4239e-02,  1.6702e-02, -7.1894e-02,  2.0208e-02,\n",
       "                       9.0863e-02,  1.3597e-01, -9.9322e-02, -1.6042e-02,  6.8235e-02,\n",
       "                      -9.2612e-02, -4.6779e-02, -3.2105e-02, -1.0956e-02,  5.6499e-02,\n",
       "                       1.0708e-01,  9.0289e-02, -9.0793e-02,  4.6324e-02,  1.6101e-02,\n",
       "                      -1.1745e-01,  5.9167e-04, -1.0923e-01,  1.0491e-01, -5.2613e-02,\n",
       "                      -5.6532e-02,  1.8847e-02, -4.7819e-02,  1.2550e-01,  3.8710e-02,\n",
       "                      -9.0593e-03, -3.8006e-02, -2.3043e-02,  1.2344e-01,  1.0529e-02,\n",
       "                       1.2590e-01,  5.1368e-02,  1.0742e-02,  5.3663e-02, -1.0095e-01,\n",
       "                       4.6709e-02,  6.8279e-02, -1.0745e-01,  1.0039e-01,  5.9389e-02,\n",
       "                      -9.9320e-02, -8.6539e-02,  1.1545e-01,  1.2182e-01,  3.3682e-02,\n",
       "                      -2.3836e-02, -1.1808e-01, -1.1853e-01,  2.0323e-02,  3.6417e-02,\n",
       "                       1.2129e-01, -1.1222e-01, -4.5970e-02, -1.1083e-01, -1.0771e-01,\n",
       "                       1.1707e-01, -4.1592e-02, -1.7260e-02, -7.4603e-02, -1.0543e-02,\n",
       "                      -1.0832e-02,  3.9907e-02, -9.0008e-02, -2.2720e-02, -9.7201e-02,\n",
       "                       5.1805e-02, -1.0487e-01, -1.3355e-02,  1.0561e-01, -2.0377e-03,\n",
       "                      -1.0055e-01,  1.3228e-01,  7.5927e-02,  7.5686e-02, -2.0551e-02,\n",
       "                       1.1222e-01,  1.0708e-01,  1.2696e-01,  4.5612e-02, -3.7094e-02,\n",
       "                       9.4711e-02, -8.4061e-02,  6.2915e-02, -9.6451e-02,  7.6270e-02,\n",
       "                      -2.5496e-02, -1.0884e-01,  1.0260e-01,  3.5907e-02,  1.3365e-01,\n",
       "                      -8.0174e-02, -6.9388e-02, -7.2127e-02, -5.7266e-02,  1.0338e-01,\n",
       "                      -2.4904e-02, -9.1301e-02, -1.3524e-01,  7.9525e-02,  3.4991e-02,\n",
       "                      -9.6429e-02,  5.1640e-02,  5.8053e-02, -4.4430e-02, -1.2078e-01,\n",
       "                      -1.1460e-02,  2.1972e-02,  7.6108e-02, -2.6295e-02, -7.6200e-02,\n",
       "                      -7.7145e-02, -7.6156e-02, -3.2661e-02,  1.2033e-01,  1.1140e-02,\n",
       "                       1.9784e-02, -5.1275e-02,  9.7596e-02,  5.8264e-02,  1.1555e-01,\n",
       "                      -4.4698e-02, -8.3949e-03, -1.1648e-01,  1.1524e-01,  1.3665e-01,\n",
       "                       1.3122e-01, -2.9743e-03, -4.8238e-02,  7.8895e-03,  9.7860e-03,\n",
       "                      -1.2530e-01,  1.0210e-01, -1.0556e-01,  8.1224e-02, -1.0699e-01,\n",
       "                       6.0780e-02, -4.8383e-02,  1.2737e-02,  6.4926e-03, -1.1783e-01,\n",
       "                      -1.6845e-02,  9.5399e-02,  8.3796e-03, -4.2188e-02, -7.4578e-02,\n",
       "                      -7.5836e-02, -1.9222e-02, -3.5255e-02,  1.4507e-02, -6.1228e-02,\n",
       "                       8.6097e-02,  8.4653e-03,  2.4945e-02,  1.0272e-01,  8.2192e-02,\n",
       "                       4.4157e-02, -6.0785e-02,  2.9056e-03, -9.1287e-02, -9.6137e-02,\n",
       "                       8.4342e-02,  1.0881e-01, -4.7146e-02, -4.8265e-02,  7.7064e-02,\n",
       "                      -4.1896e-02, -3.2395e-02,  9.0491e-02,  9.8159e-02,  5.4006e-02,\n",
       "                       3.5987e-02], device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_ih_l2_reverse',\n",
       "              tensor([[-2.1167e-02, -6.0295e-02,  7.9454e-02,  ..., -1.2222e-02,\n",
       "                       -4.6275e-02,  1.2847e-01],\n",
       "                      [-8.4521e-02, -6.6541e-02, -9.1309e-02,  ..., -4.1010e-02,\n",
       "                       -1.4267e-02, -1.0312e-01],\n",
       "                      [ 2.6703e-02,  1.1073e-01, -8.9082e-02,  ..., -1.1907e-01,\n",
       "                       -8.4227e-02, -3.0997e-02],\n",
       "                      ...,\n",
       "                      [-2.8432e-02,  7.9476e-02,  7.6021e-02,  ...,  1.0134e-01,\n",
       "                        4.2066e-05, -5.5746e-02],\n",
       "                      [-1.3474e-01,  2.5174e-03, -1.2112e-02,  ...,  1.4925e-02,\n",
       "                       -5.9830e-03, -4.7029e-02],\n",
       "                      [-8.5639e-03, -7.9992e-02, -2.2317e-02,  ...,  4.3661e-02,\n",
       "                        8.6799e-02, -8.6689e-02]], device='cuda:0')),\n",
       "             ('net.lstm_stack.weight_hh_l2_reverse',\n",
       "              tensor([[ 0.0295, -0.0216,  0.0235,  ...,  0.0904, -0.0331, -0.1126],\n",
       "                      [-0.0293, -0.0583, -0.0312,  ...,  0.0537, -0.0858,  0.0509],\n",
       "                      [ 0.0287,  0.0984, -0.0161,  ...,  0.1011, -0.1036, -0.0269],\n",
       "                      ...,\n",
       "                      [-0.1210, -0.0993,  0.0858,  ...,  0.0853,  0.0696,  0.0670],\n",
       "                      [ 0.0428, -0.0759,  0.0257,  ...,  0.0120,  0.0661, -0.0885],\n",
       "                      [ 0.1007, -0.1031, -0.0813,  ...,  0.1119,  0.1155, -0.0691]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_ih_l2_reverse',\n",
       "              tensor([-0.0828, -0.0282,  0.0068,  0.0096,  0.0890, -0.0929, -0.1080, -0.0332,\n",
       "                       0.0176,  0.0173, -0.0050,  0.0553, -0.0969,  0.0523,  0.1366,  0.1340,\n",
       "                      -0.0662, -0.0180,  0.0224, -0.0267,  0.0993,  0.0741,  0.1190, -0.0896,\n",
       "                      -0.0014,  0.1102,  0.0961,  0.0350,  0.0959,  0.0882,  0.1212,  0.1289,\n",
       "                      -0.1135, -0.1023,  0.0339,  0.0484,  0.0271,  0.0693,  0.1059,  0.0943,\n",
       "                      -0.0060, -0.0841, -0.0969, -0.0390, -0.0889,  0.0946,  0.0542, -0.0788,\n",
       "                       0.1069, -0.0707, -0.0733,  0.1184, -0.0672, -0.0081, -0.0312, -0.0490,\n",
       "                       0.0879,  0.0293, -0.0208, -0.1052, -0.0850, -0.0218, -0.0454,  0.0124,\n",
       "                      -0.1064,  0.0061,  0.0728,  0.0223,  0.1216,  0.0058, -0.0210,  0.0023,\n",
       "                      -0.1102,  0.0661,  0.0902, -0.0459, -0.0771, -0.0940,  0.0330,  0.0314,\n",
       "                      -0.1096, -0.0988,  0.0463, -0.0588,  0.0130,  0.0622, -0.1000, -0.0776,\n",
       "                      -0.0132, -0.1100,  0.0793,  0.0869, -0.1055,  0.1286,  0.0297,  0.0389,\n",
       "                      -0.0828,  0.0728,  0.0019, -0.0482, -0.1120, -0.0299, -0.1093, -0.1189,\n",
       "                      -0.0759, -0.0240,  0.1280, -0.0599, -0.0102,  0.0707, -0.0277, -0.0655,\n",
       "                      -0.0251,  0.1081,  0.1200,  0.0911,  0.0552, -0.1214,  0.0697, -0.0013,\n",
       "                       0.0848,  0.0755,  0.1000,  0.0733, -0.0735, -0.0284, -0.0762, -0.0885,\n",
       "                       0.0686, -0.0972, -0.0915, -0.0675,  0.0272, -0.0689, -0.0832, -0.0828,\n",
       "                       0.0645, -0.0262, -0.0698, -0.1144, -0.0078, -0.0678,  0.0664, -0.0108,\n",
       "                      -0.0648, -0.0233, -0.0796, -0.1094,  0.0133, -0.0660,  0.1252,  0.0737,\n",
       "                       0.0341,  0.0144,  0.1021, -0.0522,  0.0134, -0.0842, -0.0904, -0.0009,\n",
       "                       0.0471, -0.0689,  0.0651,  0.1023, -0.0334, -0.1211, -0.0699,  0.0867,\n",
       "                       0.0576, -0.0577, -0.0454, -0.0090,  0.0310,  0.0418, -0.1330, -0.0333,\n",
       "                       0.0894,  0.0517, -0.0578, -0.1340,  0.0400, -0.0345,  0.0134,  0.0716,\n",
       "                       0.0898,  0.0494,  0.0504,  0.1137, -0.0042, -0.0717,  0.0742, -0.0331,\n",
       "                      -0.0639, -0.1124,  0.0659, -0.0591,  0.1122,  0.0756,  0.0919,  0.0024,\n",
       "                       0.0024, -0.0774, -0.0503, -0.0308, -0.0035, -0.0376, -0.0186, -0.0495,\n",
       "                       0.0905, -0.0898, -0.0097,  0.0061,  0.1183, -0.0494, -0.1121,  0.0545,\n",
       "                      -0.0969, -0.1036, -0.1292, -0.0655,  0.0051, -0.0747, -0.1094,  0.0587,\n",
       "                      -0.1123, -0.1027, -0.0994, -0.0109,  0.0769, -0.0513, -0.0319,  0.0406,\n",
       "                      -0.0253, -0.0754,  0.0889, -0.0496, -0.0787,  0.1223,  0.0060,  0.0011,\n",
       "                       0.1245,  0.0386, -0.1081, -0.0168, -0.0455,  0.0407,  0.0594, -0.0744,\n",
       "                       0.1077,  0.1146,  0.0845,  0.1184,  0.0780,  0.0220, -0.0809,  0.0886],\n",
       "                     device='cuda:0')),\n",
       "             ('net.lstm_stack.bias_hh_l2_reverse',\n",
       "              tensor([-0.0136,  0.0020, -0.1024, -0.0101,  0.0672,  0.0565, -0.0631, -0.0681,\n",
       "                      -0.0819,  0.0932,  0.0316,  0.0034, -0.0148, -0.0891, -0.0993,  0.1011,\n",
       "                      -0.0283,  0.1009, -0.0573, -0.0413,  0.0607,  0.0388, -0.0084,  0.0743,\n",
       "                      -0.0577, -0.0647,  0.1169,  0.0589, -0.0857, -0.0008,  0.0041, -0.0356,\n",
       "                       0.0361, -0.0430, -0.0817,  0.0657, -0.0936, -0.0314, -0.0426,  0.0635,\n",
       "                       0.1202, -0.1240,  0.0508, -0.0881, -0.0847,  0.1206, -0.0431, -0.0647,\n",
       "                       0.0496, -0.1059, -0.0290,  0.0704,  0.0859,  0.0032,  0.1238, -0.0042,\n",
       "                      -0.0991, -0.0432,  0.1306, -0.0815,  0.1115,  0.0188,  0.0222,  0.0626,\n",
       "                      -0.0593, -0.0584, -0.0749,  0.0300, -0.0610,  0.1301,  0.1284, -0.0296,\n",
       "                       0.0089,  0.0089,  0.0474, -0.0507, -0.0062, -0.0949, -0.1049,  0.0098,\n",
       "                       0.0167,  0.1292, -0.0167,  0.0179, -0.0479,  0.0539,  0.0085, -0.0378,\n",
       "                      -0.0025,  0.1031, -0.0547,  0.0077, -0.0981, -0.0728, -0.0455,  0.0749,\n",
       "                      -0.1282, -0.0262, -0.0011, -0.1020, -0.0277,  0.0826,  0.0699, -0.0829,\n",
       "                      -0.0465, -0.1086, -0.1088,  0.0614,  0.0267,  0.0095,  0.0787, -0.0664,\n",
       "                      -0.0546, -0.0839, -0.0680, -0.0790,  0.0789,  0.0922,  0.1115, -0.1088,\n",
       "                       0.0897,  0.0986,  0.0155,  0.0583,  0.0062, -0.1012,  0.0063, -0.0469,\n",
       "                      -0.0833, -0.1244,  0.0201, -0.0125, -0.0343,  0.0193,  0.0770, -0.0387,\n",
       "                      -0.0090, -0.0800,  0.0827, -0.1264,  0.0998, -0.1041,  0.0315, -0.0355,\n",
       "                      -0.0996, -0.0504,  0.0298,  0.0541,  0.0969, -0.0168,  0.0460, -0.0079,\n",
       "                       0.1338,  0.1050,  0.0265,  0.1095, -0.0067, -0.1030,  0.0754, -0.0074,\n",
       "                       0.0775, -0.0623,  0.0011, -0.0432,  0.0622,  0.0884, -0.0296,  0.0872,\n",
       "                       0.0618,  0.0679,  0.0818, -0.0797, -0.0679, -0.0816, -0.0005, -0.1127,\n",
       "                       0.1291,  0.0002,  0.1340, -0.0345,  0.0524,  0.0515,  0.0158, -0.0574,\n",
       "                       0.0442,  0.1115, -0.0053, -0.0581, -0.0212, -0.0715, -0.0466, -0.0949,\n",
       "                       0.0231,  0.0138,  0.1019, -0.0305, -0.1170,  0.1229,  0.1243,  0.0853,\n",
       "                       0.0252,  0.1116,  0.1336,  0.0390,  0.0322, -0.0030, -0.0932,  0.0597,\n",
       "                      -0.0774, -0.0064,  0.1207,  0.1302,  0.0078,  0.0061, -0.0626, -0.0059,\n",
       "                      -0.0598,  0.1352,  0.0381, -0.0800,  0.1161,  0.0429,  0.1318, -0.0450,\n",
       "                       0.0938,  0.0022,  0.1287, -0.0723, -0.0195,  0.1291,  0.0935, -0.0948,\n",
       "                      -0.0231,  0.0275,  0.0158,  0.0144,  0.1017,  0.1274,  0.0538, -0.0930,\n",
       "                      -0.0647,  0.1262, -0.0424,  0.1229,  0.0970, -0.1294, -0.0939, -0.0794,\n",
       "                      -0.1081,  0.0581,  0.0761,  0.0545,  0.0413, -0.0831, -0.0111,  0.0191],\n",
       "                     device='cuda:0')),\n",
       "             ('net.linear.weight',\n",
       "              tensor([[ 0.0151, -0.0556, -0.0003,  ...,  0.0291,  0.0412,  0.0742],\n",
       "                      [ 0.0353,  0.0193, -0.0470,  ..., -0.0788,  0.0328,  0.0551],\n",
       "                      [ 0.0130,  0.0002,  0.0445,  ..., -0.0691, -0.0240, -0.0134],\n",
       "                      ...,\n",
       "                      [ 0.0045,  0.0697,  0.0754,  ..., -0.0205,  0.0425,  0.0115],\n",
       "                      [ 0.0184,  0.0640, -0.0053,  ...,  0.0245,  0.0208, -0.0311],\n",
       "                      [-0.0584, -0.0375,  0.0002,  ..., -0.0181,  0.0035, -0.0547]],\n",
       "                     device='cuda:0')),\n",
       "             ('net.linear.bias',\n",
       "              tensor([ 0.0904,  0.0613,  0.0592, -0.0919,  0.0421, -0.0074, -0.0531, -0.0672,\n",
       "                       0.0123,  0.0209, -0.0297,  0.0359,  0.0681, -0.0006, -0.0559,  0.0298,\n",
       "                       0.0208, -0.0560,  0.0052,  0.0323, -0.0423, -0.0841, -0.0563,  0.0700,\n",
       "                       0.0201, -0.0142, -0.0530, -0.0459, -0.0171, -0.0590,  0.0741, -0.0332,\n",
       "                       0.0220,  0.0361, -0.0176,  0.0469, -0.0587, -0.0500,  0.0177,  0.0561,\n",
       "                       0.0668, -0.0359, -0.0594,  0.0577, -0.0887, -0.0877,  0.0497, -0.0800,\n",
       "                       0.0538,  0.0143,  0.0422, -0.0386,  0.0525, -0.0809,  0.0366, -0.0360,\n",
       "                       0.0179, -0.0488, -0.0053,  0.0511, -0.0769,  0.0069,  0.0483,  0.0625,\n",
       "                       0.0220, -0.0817, -0.0686, -0.0625], device='cuda:0'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3\n",
    "\n",
    "Based on [this](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html#nn-module-from-checkpoint) and [that](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html).\n",
    "\n",
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters', 'datamodule_hparams_name', 'datamodule_hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_weights = {k.replace('net.', ''): v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"net.\")}\n",
    "# I remove 'net.' prefix because of later loading step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = load_alphabet(BASE_PATH / 'alphabet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Carbune2020NetAttempt1(\n",
    "    number_of_channels=3,\n",
    "    nodes_per_layer=64,\n",
    "    number_of_layers=3,\n",
    "    dropout=0.0,\n",
    "    alphabet=alphabet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(net_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Carbune2020NetAttempt1(\n",
       "  (log_softmax): LogSoftmax(dim=2)\n",
       "  (lstm_stack): LSTM(3, 64, num_layers=3, bidirectional=True)\n",
       "  (linear): Linear(in_features=128, out_features=82, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.online_handwriting_datamodule import IAMOnDBDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdisk/s1691089/venvs/carbune2020/lib/python3.10/site-packages/torch/utils/data/dataset.py:414: UserWarning: Length of split at index 2 is 0. This might result in an empty dataset.\n",
      "  warnings.warn(f\"Length of split at index {i} is 0. \"\n"
     ]
    }
   ],
   "source": [
    "dm = IAMOnDBDataModule(\n",
    "    '../data/datasets/IAM-OnDB',\n",
    "    batch_size=64,\n",
    "    train_val_test_split=[0.8, 0.2, 0],\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    # limit=200,\n",
    "    limit=3000,\n",
    "    transform='carbune2020_xyn',\n",
    ")\n",
    "dm.setup()\n",
    "dl = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    sample_batched = next(iter(dl))\n",
    "batch = sample_batched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Carbune2020NetAttempt1(\n",
       "  (log_softmax): LogSoftmax(dim=2)\n",
       "  (lstm_stack): LSTM(3, 64, num_layers=3, bidirectional=True)\n",
       "  (linear): Linear(in_features=128, out_features=82, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = model(sample_batched['ink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([659, 64, 82])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = checkpoint['hyper_parameters']['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedyCTCDecoder()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[71, 73, 68,  ...,  0,  0,  0],\n",
       "        [35,  1,  5,  ...,  0,  0,  0],\n",
       "        [59, 53, 74,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [55, 67, 65,  ...,  0,  0,  0],\n",
       "        [70, 57, 75,  ...,  0,  0,  0],\n",
       "        [53, 54, 67,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batched['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would need alphabet (or alphabet_mapper) now to do proper inference.\n",
    "\n",
    "G\"pytorch lightning add data to checkpoint -> add alphabet from datamodule\"\n",
    "\n",
    "[This](https://github.com/Lightning-AI/pytorch-lightning/discussions/10172) could be the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.tokenisers import AlphabetMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_mapper = AlphabetMapper( alphabet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_texts = decoder(log_softmax, alphabet_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23,\n",
       " 26,\n",
       " 22,\n",
       " 42,\n",
       " 27,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 34,\n",
       " 34,\n",
       " 29,\n",
       " 25,\n",
       " 33,\n",
       " 20,\n",
       " 31,\n",
       " 21,\n",
       " 33,\n",
       " 25,\n",
       " 35,\n",
       " 38,\n",
       " 27,\n",
       " 29,\n",
       " 27,\n",
       " 24,\n",
       " 29,\n",
       " 11,\n",
       " 22,\n",
       " 37,\n",
       " 34,\n",
       " 30,\n",
       " 5,\n",
       " 23,\n",
       " 21,\n",
       " 22,\n",
       " 29,\n",
       " 37,\n",
       " 23,\n",
       " 41,\n",
       " 36,\n",
       " 41,\n",
       " 32,\n",
       " 23,\n",
       " 28,\n",
       " 23,\n",
       " 21,\n",
       " 28,\n",
       " 28,\n",
       " 35,\n",
       " 28,\n",
       " 27,\n",
       " 35,\n",
       " 27,\n",
       " 33,\n",
       " 27,\n",
       " 31,\n",
       " 29,\n",
       " 33,\n",
       " 29,\n",
       " 46,\n",
       " 35,\n",
       " 22,\n",
       " 27,\n",
       " 22,\n",
       " 34]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['label_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Could be pre-computed (using list0 in batch to avoid endless recomputation\n",
    "labels = []\n",
    "for i_batch in range(log_softmax.shape[1]):\n",
    "    label_length = batch['label_lengths'][i_batch]\n",
    "    label = batch['label'][i_batch, :label_length]\n",
    "    label = [ alphabet_mapper.index_to_character(c) for c in label ]\n",
    "    label = \"\".join(label)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prmmlpb eb eZa jroaboba',\n",
       " 'H &a jZhb vlr jfpboZ[ib- H',\n",
       " 'dZsb Z ]ov Zka aolmmba',\n",
       " 'iltbpq mlpfqflk lc qeb ]ZqbkZ fp qeb erjrp',\n",
       " 'Arq fq tZp Z ebZsbkiv slf]b',\n",
       " 'mlppf[ib+ ql pmbZh clo efjpbic-',\n",
       " 'kfpba fq Zp [bfkd ZmmolufjZqbiv',\n",
       " 'qebob tbob tfkbp ql loabo- Llpq',\n",
       " 'Mlq pbbk pr]e Z mbocb]qiv [ZiZk]ba',\n",
       " 'tbob bZqfkd fk LfqwoZgfj + ql pelt',\n",
       " 'Sebpb iZpq Rfjlk tbkq qeolrde',\n",
       " 'Aoltk clobpq plfi lc dlla',\n",
       " 'lro Ziifbp lo Lo- Jeorpe]ebs , lo',\n",
       " 'Zka fp teZq fp jbZkq',\n",
       " 'tlk&q tZkq jb ebob qljloolt+ Zp',\n",
       " 'RbZo]e lrq fk tfpalj-',\n",
       " 'piZsbp- Seb Z]nrfpfqflk lc piZsbp',\n",
       " 'bccb]qfsbiv ]lloafkZqbp Z',\n",
       " 'jlabpq BeZoqboelrpb,pqobbq+ Klkalk+',\n",
       " 'efp fjZdb tfqe mbqriZkq ]lk]bkqoZqflk-',\n",
       " 'AvwZkqfkb qfjbp- ?ii qelrde',\n",
       " 'Ofboob&p [Zo ZdZfk Zka ZdZfk-',\n",
       " 'RbZiaoZrdeq Kqa ?ipl jZhb Z',\n",
       " 'ql qeb sfqZi nrbpqflk lc',\n",
       " 'sbuZqflk- Sefp fp qeb mol[ibj',\n",
       " \"]iZvp- '0(-\",\n",
       " 'efp ]elf]b eb olpb Zka',\n",
       " 'mZoqba ifhb lia cofbkap- Gb prddbpqba',\n",
       " 'qeZq tef]e qeb Ibtp qllh rmlk qebj',\n",
       " 'Efopq ql [fka qebj ql eZsb qeb',\n",
       " '[Z]h-',\n",
       " 'FZccbo&p Dvbp kZooltba-',\n",
       " 'mriiba colj ebo kb]h-',\n",
       " 'eZsb [bbk abofsba colj',\n",
       " 'eb fp [lok- LZv[b pl Afii+ eb',\n",
       " 'Nsbo qebob qeb ]lpq fp Z[lrq # 06 -//',\n",
       " 'jZh ilsb &p Zk Zoq- ?ka',\n",
       " 'vbiiltba [v orpq+ elrpba qeb avfkd bj[bop',\n",
       " 'ZqqoZ]qfsb fk fqp cofbkaifkbpp- Sefp',\n",
       " 'Lo - Ellq & p ifkb tfii [b qeZq Zp KZ[lro',\n",
       " 'qeb ]efkbp Zka qeb [lqqlj peZmba',\n",
       " 'qeb procZ]b+\" peb pZfa-',\n",
       " 'vlr dl lsbo- Gb qllh Z ciZph',\n",
       " ']ljmZoqjbkq lc qeb ]Zo-',\n",
       " 'ZdZfk clo mrkfpejbkq;',\n",
       " 'illhba Zq efj- IlZkkZ&p Dvbp',\n",
       " 'eZa clrka jbppZdbp pbkq colj',\n",
       " 'Hq fp qeb crii Zka cfkZi obsbiZqflk',\n",
       " 'Hk qeb jfaaib lc qeb glrokbv',\n",
       " 'lc\" jlob qeZk prccf]fbk]v \"',\n",
       " 'fkslirkqZofiv Zp eb illhba Zq ebo ,',\n",
       " 'qebv tlria prpmb]q klqefkd-',\n",
       " 'jlob ifhb eljb- & ?cqbo Zii+ tebk',\n",
       " 'pmbZh Vbipe tZp fk]iraba Zp',\n",
       " '\"Sefkh qebob &p HkafZkp Z[lrq;\"',\n",
       " 'ebZoa efj pZv- \"Rqfii jZhfkd,',\n",
       " ']lria [b oZfpba lo iltboba Zp qeb',\n",
       " 'krj[bo lc miZvbop tlria [b fk',\n",
       " \"[roabkp lc Ddvmq- '1(- H tfii ofa vlr lc qebfo\",\n",
       " 'pmb]qZqlop tbob eZoa tfqe afpZpqbo-',\n",
       " 'Vb tbob tlhbk rm qtf]b',\n",
       " ']ljjbkqp colj ]fqv cofbkap-',\n",
       " 'obtZoa- SeZq jbZkp qeb',\n",
       " 'Z[lrq ebo rmqeoltk ebZa- \"Vev klq+']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer = char_error_rate(preds=decoded_texts, target=labels)\n",
    "wer = word_error_rate(preds=decoded_texts, target=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8469), tensor(0.9971))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer, wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt n\n",
    "\n",
    "Check point 3 references 1-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
