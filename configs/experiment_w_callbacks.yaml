defaults:
  - extras: default
  - paths: default
  - logger: tensorboard
  - hydra: default
  - callbacks:
    - model_checkpoint
    - measure_speed
  - _self_

tags: ["experiment2"]

seed: 42

data:
  _target_: src.data.online_handwriting_datamodule.IAMOnDBDataModule
  data_dir: ${paths.data_dir}/datasets/IAM-OnDB
  batch_size: 64
  train_val_test_split: [10, 0, 0]
  num_workers: 0
  pin_memory: False
  limit: 10
  transform: "iam_xy"

model:
  _target_: src.models.carbune_module.CarbuneLitModule2
  decoder:
    _target_: src.utils.decoders.GreedyCTCDecoder
  net:
    _target_: src.models.components.carbune2020_net.Carbune2020NetAttempt1
    _partial_: true
    nodes_per_layer: 64
    number_of_layers: 3
    dropout: 0.0
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.0
  scheduler: null
  # scheduler:
  #   _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  #   _partial_: true
  #   mode: min
  #   factor: 0.1
  #   patience: 10

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1 # prevents early stopping
  max_epochs: 10000
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  deterministic: False
  log_every_n_steps: 1

task_name: "train"

train: True

ckpt_path: null

callbacks:
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch{epoch:06d}"
    every_n_epochs: 5
    save_top_k: -1
    auto_insert_metric_name: False